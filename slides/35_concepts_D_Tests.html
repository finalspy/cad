<!-- Slide d'introduction g√©n√©rale -->
<section data-background-image="/public/images/titre_concepts.jpg"
          data-background-size="cover"
          data-background-opacity="0.5">
  <h2>Concepts cl√©s</h2>
  <ul>
    <li>üî∫ Th√©or√®mes fondamentaux</li>
    <li>üåê Concepts et Techniques Cl√©s</li>
    <li>üß© Architecture et Design</li>
    <li>üõ°Ô∏è R√©silience et Scalabilit√©</li>
    <li><b>üß™ Tests et Observabilit√©</b></li>
    <li>üß† Gouvernance et √âquipes</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Voici les cinq grands ensembles qui structurent ce module.</li>
      <li>Nous allons explorer chaque groupe de concepts √† travers des exemples concrets.</li>
    </ul>
  </aside>
</section>

<!-- SECTION Testabilit√© & Observabilit√© -->
<section>
  <h2>üß™ Testabilit√© et Observabilit√©</h2>
  <aside class="notes">
    Garantir la qualit√©, la maintenabilit√© et la compr√©hension d'un syst√®me distribu√© n√©cessite une approche globale du test et de l'observabilit√©.
  </aside>
</section>

<!-- Testabilit√© ‚Äî Th√©orie Aper√ßu -->
<section>
  <h2>Testabilit√© ‚Äî Aper√ßu</h2>
  <ul>
    <li>Unit Tests</li>
    <li>Integration Tests</li>
    <li>Contract Tests</li>
    <li>E2E Tests</li>
    <li>Performance Testing</li>
    <li>Chaos Engineering</li>
  </ul>
  <aside class="notes">
    Les diff√©rents types de tests r√©pondent √† des objectifs et des risques diff√©rents. Bien les distinguer est la cl√© d'une strat√©gie de test efficace.
  </aside>
</section>

<!-- Unit Tests: But -->
<section>
  <h2>Unit Tests ‚Äî But</h2>
  <ul>
    <li>V√©rifier le comportement d'unit√© isol√©e (fonction, m√©thode, classe)</li>
    <li>D√©tecter rapidement les r√©gressions</li>
    <li>Assurer un feedback rapide en d√©veloppement</li>
  </ul>
  <aside class="notes">
    Les tests unitaires valident une logique sans d√©pendance externe. Ils sont la premi√®re ligne de d√©fense contre les bugs.
  </aside>
</section>
<!-- Unit Tests: Avantages -->
<section>
  <h2>Unit Tests ‚Äî Avantages</h2>
  <ul>
    <li>Tr√®s rapides (ms √† s)</li>
    <li>Permettent le TDD</li>
    <li>Documentation vivante du code</li>
  </ul>
  <aside class="notes">
    L'ex√©cution rapide permet des cycles courts : commit, test, correction, recommit. Les tests unitaires facilitent le refactoring.
  </aside>
</section>
<!-- Unit Tests: Inconv√©nients & Limites -->
<section>
  <h2>Unit Tests ‚Äî Limites & √âcueils</h2>
  <ul>
    <li>Ne couvrent pas les interactions r√©elles</li>
    <li>Fausses assurances (tests trop ‚Äúmock√©s‚Äù)</li>
    <li>Peuvent devenir fragiles si couplage √©lev√©</li>
  </ul>
  <aside class="notes">
    Trop de mocks ou de stubs = perte de valeur du test. Les tests unitaires ne remplacent pas les tests d'int√©gration ou E2E.
  </aside>
</section>
<!-- Unit Tests: Bonnes pratiques -->
<section>
  <h2>Unit Tests ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>Tester un seul comportement par test</li>
    <li>Pas de d√©pendance r√©seau ou fichier</li>
    <li>Nommage clair des cas de test</li>
    <li>Inclure dans CI/CD</li>
  </ul>
  <aside class="notes">
    Un test doit √©chouer pour une seule raison. Les tests unitaires doivent √™tre maintenus √† chaque refactoring.
  </aside>
</section>

<!-- Integration Tests: But -->
<section>
  <h2>Integration Tests ‚Äî But</h2>
  <ul>
    <li>Valider l'interaction entre plusieurs modules/services</li>
    <li>V√©rifier l'int√©gration avec bases de donn√©es, files, APIs externes</li>
  </ul>
  <aside class="notes">
    Les tests d'int√©gration attrapent les bugs d'assemblage qui √©chappent aux tests unitaires.
  </aside>
</section>
<!-- Integration Tests: Avantages -->
<section>
  <h2>Integration Tests ‚Äî Avantages</h2>
  <ul>
    <li>D√©tecte les probl√®mes de configuration</li>
    <li>Rep√®re les incompatibilit√©s de sch√©ma, protocole</li>
    <li>Permet de tester l'environnement de production ‚Äúsimul√©‚Äù</li>
  </ul>
  <aside class="notes">
    Les outils comme Testcontainers permettent de simuler les environnements r√©els via Docker.
  </aside>
</section>
<!-- Integration Tests: Inconv√©nients & √âcueils -->
<section>
  <h2>Integration Tests ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Plus lents et co√ªteux (setup/teardown DB, r√©seau)</li>
    <li>Flakiness si d√©pendances externes instables</li>
    <li>Difficult√© √† isoler la cause d'un √©chec</li>
  </ul>
  <aside class="notes">
    Attention √† ne pas tout tester via l'int√©gration : la pyramide des tests reste valide.
  </aside>
</section>
<!-- Integration Tests: Bonnes pratiques -->
<section>
  <h2>Integration Tests ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>Utiliser des bases ou conteneurs √©ph√©m√®res</li>
    <li>Nettoyer les donn√©es entre les tests</li>
    <li>Tracer chaque √©tape (logs d√©di√©s)</li>
    <li>Limiter la port√©e : pas de E2E d√©guis√© !</li>
  </ul>
  <aside class="notes">
    Les tests d'int√©gration doivent rester pr√©visibles, reproductibles, et rapides autant que possible.
  </aside>
</section>

<!-- Contract Tests: But -->
<section>
  <h2>Contract Tests ‚Äî But</h2>
  <ul>
    <li>Garantir que l'API (producteur) respecte bien le contrat attendu par les consommateurs</li>
    <li>√âviter les r√©gressions d'interface lors des √©volutions</li>
  </ul>
  <aside class="notes">
    Le contract testing est critique en microservices et plateformes ouvertes (API publiques).
  </aside>
</section>
<!-- Contract Tests: Avantages -->
<section>
  <h2>Contract Tests ‚Äî Avantages</h2>
  <ul>
    <li>Valide l'accord sur les formats d'√©change</li>
    <li>Permet la livraison ind√©pendante des services</li>
    <li>D√©tecte les breaking changes avant mise en production</li>
  </ul>
  <aside class="notes">
    Les outils comme Pact facilitent la v√©rification automatique des contrats.
  </aside>
</section>
<!-- Contract Tests: Inconv√©nients & √âcueils -->
<section>
  <h2>Contract Tests ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Couverture limit√©e √† l'API contractuelle</li>
    <li>Peut donner un faux sentiment de s√©curit√©</li>
    <li>Gestion complexe des versions de contrat</li>
  </ul>
  <aside class="notes">
    Le contract testing ne remplace pas l'int√©gration r√©elle : il garantit l'interface, pas le comportement global.
  </aside>
</section>
<!-- Contract Tests: Bonnes pratiques -->
<section>
  <h2>Contract Tests ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>Centraliser les contrats (Pact Broker‚Ä¶)</li>
    <li>V√©rifier en CI/CD √† chaque commit</li>
    <li>Mettre √† jour √† chaque changement d'API</li>
    <li>Inclure les cas limites et d'erreur</li>
  </ul>
  <aside class="notes">
    Toujours synchroniser la documentation de l'API et les tests de contrat.
  </aside>
</section>

<!-- E2E Tests: But -->
<section>
  <h2>E2E Tests ‚Äî But</h2>
  <ul>
    <li>Valider le parcours utilisateur de bout en bout</li>
    <li>D√©tecter les r√©gressions sur le produit complet</li>
  </ul>
  <aside class="notes">
    Les tests E2E simulent le comportement d'un utilisateur r√©el √† travers l'UI ou l'API publique.
  </aside>
</section>
<!-- E2E Tests: Avantages -->
<section>
  <h2>E2E Tests ‚Äî Avantages</h2>
  <ul>
    <li>V√©rifie le fonctionnement global</li>
    <li>Capte les bugs ‚Äúint√©gration invisible‚Äù</li>
    <li>Utilisables comme tests de non-r√©gression</li>
  </ul>
  <aside class="notes">
    Ils rassurent sur l'exp√©rience r√©elle de l'utilisateur final, surtout apr√®s refonte ou migration.
  </aside>
</section>
<!-- E2E Tests: Inconv√©nients & √âcueils -->
<section>
  <h2>E2E Tests ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Tr√®s lents, fragiles (flaky) sur CI/CD</li>
    <li>Complexit√© de setup et maintenance (mock data, users, auth, etc.)</li>
    <li>Difficiles √† d√©boguer en cas d'√©chec</li>
  </ul>
  <aside class="notes">
    Le ratio recommand√© : peu de tests E2E, beaucoup de tests unitaires/int√©gration.
  </aside>
</section>
<!-- E2E Tests: Bonnes pratiques -->
<section>
  <h2>E2E Tests ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>Automatiser screenshots & logs √† l'√©chec</li>
    <li>Utiliser des environnements de staging d√©di√©s</li>
    <li>Limiter aux parcours critiques</li>
    <li>Rafra√Æchir les donn√©es et comptes entre chaque run</li>
  </ul>
  <aside class="notes">
    Les tests E2E doivent √™tre stables et apporter une vraie valeur m√©tier.
  </aside>
</section>

<!-- Performance Testing: But -->
<section>
  <h2>Performance Testing ‚Äî But</h2>
  <ul>
    <li>√âvaluer la robustesse sous charge : pics, volume, stress, endurance</li>
    <li>Identifier les goulets d'√©tranglement</li>
  </ul>
  <aside class="notes">
    Simuler la mont√©e en charge ou l'activit√© r√©elle est essentiel pour pr√©venir les d√©faillances en production.
  </aside>
</section>
<!-- Performance Testing: Avantages -->
<section>
  <h2>Performance Testing ‚Äî Avantages</h2>
  <ul>
    <li>Pr√©dire le comportement r√©el en production</li>
    <li>Ajuster la capacit√© ou le code avant l'incident</li>
    <li>Optimiser le co√ªt d'infrastructure</li>
  </ul>
  <aside class="notes">
    Le monitoring permanent est compl√©mentaire : un test de performance ponctuel ne suffit pas.
  </aside>
</section>
<!-- Performance Testing: Inconv√©nients & √âcueils -->
<section>
  <h2>Performance Testing ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Tests co√ªteux en temps et ressources</li>
    <li>R√©sultats parfois difficiles √† interpr√©ter</li>
    <li>Risques de ‚Äúpolluer‚Äù l'environnement r√©el si mal isol√©</li>
  </ul>
  <aside class="notes">
    Attention √† ne pas saturer une prod : r√©aliser les tests sur un environnement d√©di√© ou simul√©.
  </aside>
</section>
<!-- Performance Testing: Bonnes pratiques -->
<section>
  <h2>Performance Testing ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>D√©finir les SLIs/SLOs (seuils acceptables)</li>
    <li>Automatiser la g√©n√©ration de rapports</li>
    <li>Rejouer les sc√©narios sur plusieurs environnements</li>
    <li>Corr√©ler avec les m√©triques r√©elles de prod</li>
  </ul>
  <aside class="notes">
    L'automatisation et la r√©p√©tabilit√© sont cl√©s pour progresser sur la dur√©e.
  </aside>
</section>

<!-- Chaos Engineering: But -->
<section>
  <h2>Chaos Engineering ‚Äî But</h2>
  <ul>
    <li>Valider la r√©silience en conditions r√©elles d'incident</li>
    <li>Pr√©parer les √©quipes et les syst√®mes aux al√©as</li>
  </ul>
  <aside class="notes">
    L'ing√©nierie du chaos consiste √† provoquer des pannes pour observer la robustesse et la r√©action du syst√®me et de l'√©quipe.
  </aside>
</section>
<!-- Chaos Engineering: Avantages -->
<section>
  <h2>Chaos Engineering ‚Äî Avantages</h2>
  <ul>
    <li>R√©v√®le les points faibles non d√©tect√©s en test ‚Äúnormal‚Äù</li>
    <li>Culture d'am√©lioration continue</li>
    <li>Augmente la confiance lors des incidents r√©els</li>
  </ul>
  <aside class="notes">
    Netflix et d'autres pionniers montrent que ces tests sont devenus indispensables en production cloud.
  </aside>
</section>
<!-- Chaos Engineering: Inconv√©nients & √âcueils -->
<section>
  <h2>Chaos Engineering ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Peut perturber les utilisateurs si mal contr√¥l√©</li>
    <li>Complexit√© de la mise en ≈ìuvre et des sc√©narios</li>
    <li>N√©cessite une culture d'entreprise mature</li>
  </ul>
  <aside class="notes">
    √Ä ne pas pratiquer en prod sans feature flags, alerting, rollback automatis√©.
  </aside>
</section>
<!-- Chaos Engineering: Bonnes pratiques -->
<section>
  <h2>Chaos Engineering ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>D√©finir des blast radius (limites d'impact)</li>
    <li>Automatiser le retour √† l'√©tat normal</li>
    <li>Analyser chaque incident (post-mortem)</li>
    <li>Int√©grer au cycle d'am√©lioration continue</li>
  </ul>
  <aside class="notes">
    D√©marrer sur des environnements de staging, puis monter graduellement en prod.
  </aside>
</section>

<!-- Synth√®se Testabilit√© -->
<section>
  <h2>Synth√®se : pyramide des tests</h2>
  <img src="https://martinfowler.com/articles/practical-test-pyramid/test-pyramid.png" alt="Test Pyramid" style="max-width:60%">
  <ul>
    <li>Beaucoup d'unitaires, moins d'int√©gration, tr√®s peu de E2E</li>
    <li>Maintenir la rapidit√© et la robustesse du pipeline CI/CD</li>
  </ul>
  <img src="/public/images/testPyramid.png" />
  <aside class="notes">
    La pyramide des tests illustre le bon √©quilibre entre effort, couverture, co√ªt et rapidit√©.
  </aside>
</section>

<!-- Observabilit√© ‚Äî Aper√ßu -->
<section>
  <h2>Observabilit√© ‚Äî Aper√ßu</h2>
  <ul>
    <li>Logging (journalisation)</li>
    <li>Metrics (m√©triques)</li>
    <li>Tracing (tra√ßage distribu√©)</li>
    <li>Monitoring</li>
    <li>Alerting</li>
  </ul>
  <aside class="notes">
    Les cinq piliers de l'observabilit√© forment un syst√®me nerveux pour comprendre et am√©liorer une architecture distribu√©e.
  </aside>
</section>

<!-- Logging: But -->
<section>
  <h2>Logging ‚Äî But</h2>
  <ul>
    <li>Enregistrer tous les √©v√©nements importants (techniques et m√©tiers)</li>
    <li>Fournir une tra√ßabilit√© et un historique d√©taill√©</li>
  </ul>
  <aside class="notes">
    Les logs sont la premi√®re source d'information lors d'un incident : erreurs, warnings, info m√©tier.
  </aside>
</section>
<!-- Logging: Avantages -->
<section>
  <h2>Logging ‚Äî Avantages</h2>
  <ul>
    <li>Analyse rapide des incidents</li>
    <li>Auditabilit√© compl√®te</li>
    <li>Source de v√©rit√© pour les post-mortems</li>
  </ul>
  <aside class="notes">
    Avec un centralisateur (ELK, Graylog), l'analyse devient transversale et scalable.
  </aside>
</section>
<!-- Logging: Inconv√©nients & √âcueils -->
<section>
  <h2>Logging ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Volume massif : peut saturer le stockage ou le r√©seau</li>
    <li>Donn√©es sensibles expos√©es si logs non filtr√©s</li>
    <li>‚ÄúLog Spam‚Äù : bruit inutile</li>
  </ul>
  <aside class="notes">
    Les logs doivent √™tre filtr√©s, rotat√©s et surveill√©s. Ne jamais logger de secrets ou de PII sans masquage.
  </aside>
</section>
<!-- Logging: Bonnes pratiques -->
<section>
  <h2>Logging ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>Log structur√© (JSON‚Ä¶)</li>
    <li>Niveau de s√©v√©rit√© appropri√©</li>
    <li>Centralisation et rotation</li>
    <li>Masquage des donn√©es sensibles</li>
  </ul>
  <aside class="notes">
    Toujours logguer au bon niveau (error, warn, info, debug) pour ne pas polluer les analyses.
  </aside>
</section>

<!-- Metrics: But -->
<section>
  <h2>Metrics ‚Äî But</h2>
  <ul>
    <li>Mesurer l'√©tat et la performance du syst√®me</li>
    <li>Fournir des indicateurs quantitatifs : CPU, m√©moire, requ√™tes, erreurs, temps de r√©ponse‚Ä¶</li>
  </ul>
  <aside class="notes">
    Les m√©triques servent √† √©tablir des seuils, des tendances, et d√©tecter les incidents en temps r√©el.
  </aside>
</section>
<!-- Metrics: Avantages -->
<section>
  <h2>Metrics ‚Äî Avantages</h2>
  <ul>
    <li>Visualisation temps r√©el (Grafana‚Ä¶)</li>
    <li>D√©tection proactive des anomalies</li>
    <li>Base pour auto-scaling et alerting</li>
  </ul>
  <aside class="notes">
    Les m√©triques forment le socle du monitoring moderne, notamment avec Prometheus et Grafana.
  </aside>
</section>
<!-- Metrics: Inconv√©nients & √âcueils -->
<section>
  <h2>Metrics ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Trop d'indicateurs = ‚Äúmetrics fatigue‚Äù</li>
    <li>Oubli de corr√©ler m√©triques et logs</li>
    <li>Peut masquer des probl√®mes de fond (ex. ‚Äútout va bien mais prod down‚Äù)</li>
  </ul>
  <aside class="notes">
    Choisir peu de m√©triques vraiment repr√©sentatives (SLI/SLO), et les r√©√©valuer r√©guli√®rement.
  </aside>
</section>
<!-- Metrics: Bonnes pratiques -->
<section>
  <h2>Metrics ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>D√©finir des SLI/SLO (Service Level Indicators/Objectives)</li>
    <li>Automatiser les alertes sur seuils critiques</li>
    <li>Corr√©ler avec incidents et logs</li>
    <li>Revue p√©riodique des dashboards</li>
  </ul>
  <aside class="notes">
    Les m√©triques doivent √™tre actionnables et facilement accessibles √† toute l'√©quipe.
  </aside>
</section>

<!-- Tracing: But -->
<section>
  <h2>Tracing ‚Äî But</h2>
  <ul>
    <li>Reconstituer le parcours d'une requ√™te √† travers plusieurs services</li>
    <li>Diagnostiquer les ralentissements ou √©checs distribu√©s</li>
  </ul>
  <aside class="notes">
    Le tracing distribu√© permet de comprendre l'encha√Ænement exact des traitements dans une architecture microservices.
  </aside>
</section>
<!-- Tracing: Avantages -->
<section>
  <h2>Tracing ‚Äî Avantages</h2>
  <ul>
    <li>Identification des ‚Äúspans‚Äù lents</li>
    <li>D√©tection pr√©cise des goulets d'√©tranglement</li>
    <li>Visualisation graphique du parcours complet</li>
  </ul>
  <aside class="notes">
    Outils : Jaeger, Zipkin, OpenTelemetry pour tracer automatiquement chaque requ√™te.
  </aside>
</section>
<!-- Tracing: Inconv√©nients & √âcueils -->
<section>
  <h2>Tracing ‚Äî Inconv√©nients & √âcueils</h2>
  <ul>
    <li>Volume de donn√©es cons√©quent</li>
    <li>Impl√©mentation parfois complexe</li>
    <li>N√©cessite un ID de corr√©lation coh√©rent partout</li>
  </ul>
  <aside class="notes">
    Le tracing n'a de valeur que si toutes les briques du syst√®me propagent les bons identifiants.
  </aside>
</section>
<!-- Tracing: Bonnes pratiques -->
<section>
  <h2>Tracing ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>Utiliser des trace IDs globaux</li>
    <li>Automatiser l'instrumentation via SDK (OpenTelemetry‚Ä¶)</li>
    <li>Visualiser et annoter les parcours m√©tiers cl√©s</li>
  </ul>
  <aside class="notes">
    Corr√©ler syst√©matiquement traces, logs, m√©triques : c'est l'observabilit√© ‚Äú360¬∞‚Äù.
  </aside>
</section>

<!-- Monitoring & Alerting -->
<section>
  <h2>Monitoring & Alerting ‚Äî But</h2>
  <ul>
    <li>Surveiller la sant√©, la performance et la disponibilit√© du syst√®me</li>
    <li>D√©clencher des alertes lors d'anomalies ou de d√©passements de seuils</li>
  </ul>
  <aside class="notes">
    Le monitoring doit couvrir tous les environnements (dev, staging, prod) pour pr√©venir, pas seulement r√©agir.
  </aside>
</section>
<section>
  <h2>Monitoring & Alerting ‚Äî Avantages</h2>
  <ul>
    <li>Intervention rapide sur incident</li>
    <li>Indispensable pour SLA/SLO</li>
    <li>Base de la fiabilit√© op√©rationnelle</li>
  </ul>
  <aside class="notes">
    Avec alerting intelligent (Alertmanager, PagerDuty), on r√©duit le MTTR (Mean Time To Recovery).
  </aside>
</section>
<section>
  <h2>Monitoring & Alerting ‚Äî Limites & √âcueils</h2>
  <ul>
    <li>Faux positifs/faux n√©gatifs si seuils mal calibr√©s</li>
    <li>‚ÄúAlerte fatigue‚Äù si trop de notifications</li>
    <li>Oubli de monitorer les d√©pendances externes</li>
  </ul>
  <aside class="notes">
    Mieux vaut moins d'alertes bien calibr√©es, r√©guli√®rement test√©es, que trop d'alertes ignor√©es.
  </aside>
</section>
<section>
  <h2>Monitoring & Alerting ‚Äî Bonnes pratiques</h2>
  <ul>
    <li>D√©finir qui re√ßoit quelle alerte</li>
    <li>Tester les sc√©narios de bout en bout (chaos)</li>
    <li>Automatiser l'escalade si non-r√©solu</li>
    <li>Revoir p√©riodiquement la pertinence des alertes</li>
  </ul>
  <aside class="notes">
    Les alertes doivent d√©clencher une action concr√®te et utile : √©vitez les ‚Äúalertes de confort‚Äù.
  </aside>
</section>

<!-- Synth√®se Observabilit√© -->
<section>
  <h2>Synth√®se : observabilit√© 360¬∞</h2>
  <ul>
    <li>Corr√©ler logs, m√©triques, traces pour une compr√©hension globale</li>
    <li>Rendre les signaux accessibles et compr√©hensibles</li>
    <li>Automatiser la r√©action aux incidents</li>
    <li>Outils : ELK, Prometheus, Grafana, Jaeger, Alertmanager, PagerDuty‚Ä¶</li>
  </ul>
  <aside class="notes">
    L'observabilit√© moderne permet de passer de la r√©action √† la pr√©vention, et de l'incident √† l'am√©lioration continue.
  </aside>
</section>

<!-- Clarification : Logging vs Tracing -->
<section>
  <h2>Logging et Tracing : est-ce la m√™me chose ?</h2>
  <ul>
    <li>Quelle est la diff√©rence fondamentale entre logging et tracing dans un syst√®me distribu√© ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Logging vs Tracing</h2>
  <ul>
    <li>Le <b>logging</b> capture des √©v√©nements ou messages (erreurs, infos, √©tapes m√©tier) de fa√ßon lin√©aire par service ou composant.</li>
    <li>Le <b>tracing</b> reconstitue le parcours complet d'une requ√™te √† travers tous les services, en cha√Ænant les √©v√©nements corr√©l√©s par un identifiant unique (<code>traceId</code>).</li>
    <li>Conclusion : Le logging d√©crit ce qui se passe localement ; le tracing √©claire le flux global et les d√©pendances.</li>
  </ul>
</section>

<!-- Clarification : Monitoring vs Observabilit√© -->
<section>
  <h2>Monitoring et Observabilit√© : m√™me chose ?</h2>
  <ul>
    <li>En quoi le monitoring diff√®re-t-il de l'observabilit√© ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Monitoring vs Observabilit√©</h2>
  <ul>
    <li>Le <b>monitoring</b> collecte des m√©triques pr√©-d√©finies (CPU, erreurs, latence) et d√©clenche des alertes sur seuils connus.</li>
    <li>L'<b>observabilit√©</b> permet de comprendre l'√©tat interne d'un syst√®me √† partir de signaux externes : logs, m√©triques, traces. C'est une d√©marche d'analyse, pas seulement d'alerte.</li>
    <li>Conclusion : le monitoring r√©pond √† ¬´ est-ce que √ßa va ? ¬ª, l'observabilit√© √† ¬´ pourquoi √ßa va (ou non) ? ¬ª</li>
  </ul>
</section>

<!-- Clarification : Test d'int√©gration vs E2E -->
<section>
  <h2>Test d'int√©gration et E2E, est-ce pareil ?</h2>
  <ul>
    <li>Quelle diff√©rence entre test d'int√©gration et test end-to-end ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Int√©gration vs E2E</h2>
  <ul>
    <li>Le <b>test d'int√©gration</b> v√©rifie la collaboration de plusieurs composants (DB, API, files) sans forc√©ment simuler l'utilisateur final.</li>
    <li>Le <b>test E2E</b> rejoue un parcours utilisateur complet, comme en prod, de l'UI √† la DB.</li>
    <li>Conclusion : E2E = vision m√©tier r√©elle ; int√©gration = interaction technique.</li>
  </ul>
</section>

<!-- Clarification : Performance vs Chaos Testing -->
<section>
  <h2>Performance testing et Chaos engineering : m√™me finalit√© ?</h2>
  <ul>
    <li>Les tests de performance et de chaos servent-ils le m√™me but ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Performance vs Chaos</h2>
  <ul>
    <li><b>Performance testing</b> mesure les limites du syst√®me sous charge normale ou extr√™me : vitesse, capacit√©, stabilit√©.</li>
    <li><b>Chaos engineering</b> injecte des d√©faillances (pannes, latence, coupures) pour v√©rifier la r√©silience r√©elle du syst√®me.</li>
    <li>Conclusion : Performance = ¬´ jusqu'o√π √ßa tient ? ¬ª ; Chaos = ¬´ comment √ßa r√©agit en cas d'incident ? ¬ª</li>
  </ul>
</section>

<!-- Clarification : Contract vs Integration tests -->
<section>
  <h2>Contract Test vs Integration Test : ambigu√Øt√© fr√©quente</h2>
  <ul>
    <li>Un contract test garantit-il que deux services fonctionnent ensemble ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Contract vs Integration</h2>
  <ul>
    <li>Le <b>contract test</b> v√©rifie que l'API respecte bien le contrat d'√©change (formats, statuts), pas le fonctionnement global de bout en bout.</li>
    <li>L'<b>integration test</b> v√©rifie le fonctionnement r√©el entre composants interconnect√©s, y compris la configuration, la DB, le r√©seau, etc.</li>
    <li>Conclusion : Contract test = accord d'interface, Integration test = comportement global r√©el.</li>
  </ul>
</section>

<!-- Clarification : Logging vs Monitoring -->
<section>
  <h2>Logging et Monitoring : est-ce la m√™me cat√©gorie ?</h2>
  <ul>
    <li>Les logs servent-ils √† monitorer ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Logging vs Monitoring</h2>
  <ul>
    <li>Les <b>logs</b> donnent une vision fine d'√©v√©nements individuels : erreurs, actions m√©tiers, traces de debug.</li>
    <li>Le <b>monitoring</b> agr√®ge des m√©triques issues du syst√®me (et parfois des logs !) pour alerter sur un comportement anormal.</li>
    <li>Conclusion : les logs sont une source ; le monitoring est une analyse continue pour d√©tecter les incidents.</li>
  </ul>
</section>

<!-- Clarification : Metrics vs Logs -->
<section>
  <h2>Metrics vs Logs : comment choisir ?</h2>
  <ul>
    <li>Quand pr√©f√©rer collecter une m√©trique plut√¥t qu'un log ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Metrics vs Logs</h2>
  <ul>
    <li>Une <b>m√©trique</b> mesure un ph√©nom√®ne quantitatif sur la dur√©e (CPU, latence, taux d'erreur).</li>
    <li>Un <b>log</b> capture une information instantan√©e, utile pour l'analyse d√©taill√©e ou la reconstitution a posteriori.</li>
    <li>Conclusion : m√©trique = tendance ; log = d√©tail, diagnostic pr√©cis.</li>
  </ul>
</section>

<!-- Clarification : Alerting vs Monitoring -->
<section>
  <h2>Monitoring et Alerting, confusion ?</h2>
  <ul>
    <li>L'alerting est-il une partie du monitoring ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Alerting vs Monitoring</h2>
  <ul>
    <li>Le <b>monitoring</b> collecte et analyse des signaux ; l'<b>alerting</b> d√©clenche une action (notification, escalade) sur √©v√©nement anormal d√©tect√©.</li>
    <li>Conclusion : monitoring = surveillance ; alerting = r√©action automatis√©e.</li>
  </ul>
</section>

<!-- Clarification : Observability = Visibility ? -->
<section>
  <h2>Observabilit√© = Visibilit√© ?</h2>
  <ul>
    <li>Ces deux termes sont-ils interchangeables ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Observabilit√© vs Visibilit√©</h2>
  <ul>
    <li>La <b>visibilit√©</b> d√©crit la capacit√© √† voir ce qui se passe (logs, dashboards).</li>
    <li>L'<b>observabilit√©</b> est la capacit√© √† comprendre pourquoi √ßa se passe, √† partir des signaux collect√©s.</li>
    <li>Conclusion : Visibilit√© = ‚Äúvoir‚Äù ; Observabilit√© = ‚Äúcomprendre et diagnostiquer‚Äù.</li>
  </ul>
</section>

<!-- Clarification : Tests automatis√©s vs manuels -->
<section>
  <h2>Tests automatis√©s vs manuels : opposition ?</h2>
  <ul>
    <li>Les tests manuels sont-ils toujours inf√©rieurs aux tests automatis√©s ?</li>
  </ul>
</section>
<section>
  <h2>R√©ponse : Automatis√©s vs Manuels</h2>
  <ul>
    <li>Les <b>tests automatis√©s</b> assurent la r√©p√©tabilit√©, la rapidit√© et la non-r√©gression continue.</li>
    <li>Les <b>tests manuels</b> sont indispensables pour l'exploration, les cas limites, l'UX, les sc√©narios inattendus.</li>
    <li>Conclusion : compl√©mentarit√©, pas opposition.</li>
  </ul>
</section>

<!-- Quiz : QCM par type de test/obs -->
<section>
  <h2>Quiz Testabilit√© & Observabilit√©</h2>
  <ol>
    <li>√Ä quoi sert principalement un test de contrat ?</li>
    <li>Quelle est la premi√®re cause de logs inutiles ?</li>
    <li>Pourquoi limiter les tests E2E ?</li>
    <li>Quel outil pour le tracing distribu√© ?</li>
    <li>Un pi√®ge classique des alertes ?</li>
    <li>SLI/SLO : c'est quoi ?</li>
  </ol>
</section>
<section>
  <h2>R√©ponses au Quiz</h2>
  <ol>
    <li>√Ä valider le respect du format d'√©change API entre producteur et consommateur.</li>
    <li>Le log spam ou l'absence de filtrage de niveau.</li>
    <li>Parce qu'ils sont longs, fragiles, co√ªteux √† maintenir.</li>
    <li>Jaeger, Zipkin, OpenTelemetry.</li>
    <li>Le ‚Äúbruit‚Äù (trop d'alertes) : on finit par les ignorer.</li>
    <li>Indicateurs et objectifs de qualit√© de service.</li>
  </ol>
</section>

<!-- QCM 1 -->
<section>
  <h2>QCM</h2>
  <p><strong>Quel test v√©rifie l'interface d'une API sans ex√©cuter tous les modules ?</strong></p>
  <ol type="a">
    <li>Test unitaire</li>
    <li>Contract test</li>
    <li>E2E test</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Contract test</strong> (b) : Il valide le respect du contrat d'API, ind√©pendamment de l'impl√©mentation compl√®te.</p>
</section>

<!-- QCM 2 -->
<section>
  <h2>QCM</h2>
  <p><strong>Le tracing distribu√© permet de‚Ä¶</strong></p>
  <ol type="a">
    <li>Visualiser le flux complet d'une requ√™te</li>
    <li>Archiver tous les logs</li>
    <li>Surveiller l'usage CPU</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Visualiser le flux complet d'une requ√™te</strong> (a) : Le tracing reconstitue le parcours d'une requ√™te dans tout le syst√®me.</p>
</section>

<!-- QCM 3 -->
<section>
  <h2>QCM</h2>
  <p><strong>Lequel n'est pas un outil de monitoring ?</strong></p>
  <ol type="a">
    <li>Prometheus</li>
    <li>Grafana</li>
    <li>Gatling</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Gatling</strong> (c) : Gatling est un outil de tests de performance, pas de monitoring.</p>
</section>

<!-- QCM 4 -->
<section>
  <h2>QCM</h2>
  <p><strong>Pourquoi limiter le nombre de tests E2E ?</strong></p>
  <ol type="a">
    <li>C'est co√ªteux et fragile</li>
    <li>√áa garantit toute la qualit√©</li>
    <li>C'est inutile</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>C'est co√ªteux et fragile</strong> (a) : Les E2E sont longs √† ex√©cuter, sensibles √† l'environnement, et peu maintenables en grand nombre.</p>
</section>

<!-- QCM 5 -->
<section>
  <h2>QCM</h2>
  <p><strong>Une m√©trique bien choisie doit √™tre‚Ä¶</strong></p>
  <ol type="a">
    <li>Quantitative, actionnable, corr√©lable</li>
    <li>Tr√®s d√©taill√©e</li>
    <li>Enregistr√©e comme log</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Quantitative, actionnable, corr√©lable</strong> (a) : Les m√©triques servent √† piloter et alerter efficacement.</p>
</section>

<!-- QCM 6 -->
<section>
  <h2>QCM</h2>
  <p><strong>Le chaos engineering consiste √†‚Ä¶</strong></p>
  <ol type="a">
    <li>Injecter des pannes contr√¥l√©es</li>
    <li>Optimiser les performances</li>
    <li>Automatiser le monitoring</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Injecter des pannes contr√¥l√©es</strong> (a) : Le chaos engineering valide la r√©silience en conditions r√©elles.</p>
</section>

<!-- QCM 7 -->
<section>
  <h2>QCM</h2>
  <p><strong>La diff√©rence cl√© entre un log et une m√©trique ?</strong></p>
  <ol type="a">
    <li>Un log est √©v√©nementiel, la m√©trique est agr√©g√©e</li>
    <li>Un log mesure la latence</li>
    <li>Aucune</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Un log est √©v√©nementiel, la m√©trique est agr√©g√©e</strong> (a) : Les logs d√©taillent chaque √©v√©nement ; les m√©triques agr√®gent l'information.</p>
</section>

<!-- QCM 8 -->
<section>
  <h2>QCM</h2>
  <p><strong>L'observabilit√© permet‚Ä¶</strong></p>
  <ol type="a">
    <li>De diagnostiquer les causes d'incident</li>
    <li>D'√©viter les logs</li>
    <li>De remplacer les tests</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>De diagnostiquer les causes d'incident</strong> (a) : L'observabilit√© offre une compr√©hension profonde du syst√®me.</p>
</section>

<!-- QCM 9 -->
<section>
  <h2>QCM</h2>
  <p><strong>Quelle est la meilleure pratique pour le logging ?</strong></p>
  <ol type="a">
    <li>Logger tout au niveau debug</li>
    <li>Utiliser des niveaux et log structur√©</li>
    <li>Eviter toute rotation</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Utiliser des niveaux et log structur√©</strong> (b) : Les logs doivent √™tre hi√©rarchis√©s (info, warn, error‚Ä¶) et structur√©s pour l'analyse.</p>
</section>

<!-- QCM 10 -->
<section>
  <h2>QCM</h2>
  <p><strong>Un test de performance mal con√ßu peut‚Ä¶</strong></p>
  <ol type="a">
    <li>Saturer l'environnement de prod</li>
    <li>Am√©liorer l'exp√©rience utilisateur</li>
    <li>Remplacer tous les tests d'int√©gration</li>
  </ol>
</section>
<section>
  <h2>R√©ponse</h2>
  <p><strong>Saturer l'environnement de prod</strong> (a) : Mal param√©tr√©, un test de charge peut causer une vraie panne !</p>
</section>