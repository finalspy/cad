<!-- Slide d'introduction gÃ©nÃ©rale -->
<section data-background-image="/public/images/titre_concepts.jpg"
          data-background-size="cover"
          data-background-opacity="0.5">
  <h2>Concepts clÃ©s</h2>
  <ul>
    <li>ğŸ”º ThÃ©orÃ¨mes fondamentaux</li>
    <li>ğŸŒ Concepts et Techniques ClÃ©s</li>
    <li>ğŸ§© Architecture et Design</li>
    <li>ğŸ›¡ï¸ RÃ©silience et ScalabilitÃ©</li>
    <li><b>ğŸ§ª Tests et ObservabilitÃ©</b></li>
    <li>ğŸ§  Gouvernance et Ã‰quipes</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Voici les cinq grands ensembles qui structurent ce module.</li>
      <li>Nous allons explorer chaque groupe de concepts Ã  travers des exemples concrets.</li>
    </ul>
  </aside>
</section>

<!-- SECTION TestabilitÃ© & ObservabilitÃ© -->
<section>
  <h2>ğŸ§ª TestabilitÃ© et ObservabilitÃ©</h2>
  <aside class="notes">
    Garantir la qualitÃ©, la maintenabilitÃ© et la comprÃ©hension d'un systÃ¨me distribuÃ© nÃ©cessite une approche globale du test et de l'observabilitÃ©.
  </aside>
</section>

<!-- TestabilitÃ© â€” ThÃ©orie AperÃ§u -->
<section>
  <h2>TestabilitÃ© â€” AperÃ§u</h2>
  <ul>
    <li>Unit Tests</li>
    <li>Integration Tests</li>
    <li>Contract Tests</li>
    <li>E2E Tests</li>
    <li>Performance Testing</li>
    <li>Chaos Engineering</li>
  </ul>
  <aside class="notes">
    Les diffÃ©rents types de tests rÃ©pondent Ã  des objectifs et des risques diffÃ©rents. Bien les distinguer est la clÃ© d'une stratÃ©gie de test efficace.
  </aside>
</section>

<!-- Unit Tests: But -->
<section>
  <h2>Unit Tests â€” But</h2>
  <ul>
    <li>VÃ©rifier le comportement d'unitÃ© isolÃ©e (fonction, mÃ©thode, classe)</li>
    <li>DÃ©tecter rapidement les rÃ©gressions</li>
    <li>Assurer un feedback rapide en dÃ©veloppement</li>
  </ul>
  <aside class="notes">
    Les tests unitaires valident une logique sans dÃ©pendance externe. Ils sont la premiÃ¨re ligne de dÃ©fense contre les bugs.
  </aside>
</section>
<!-- Unit Tests: Avantages -->
<section>
  <h2>Unit Tests â€” Avantages</h2>
  <ul>
    <li>TrÃ¨s rapides (ms Ã  s)</li>
    <li>Permettent le TDD</li>
    <li>Documentation vivante du code</li>
  </ul>
  <aside class="notes">
    L'exÃ©cution rapide permet des cycles courtsâ€¯: commit, test, correction, recommit. Les tests unitaires facilitent le refactoring.
  </aside>
</section>
<!-- Unit Tests: InconvÃ©nients & Limites -->
<section>
  <h2>Unit Tests â€” Limites & Ã‰cueils</h2>
  <ul>
    <li>Ne couvrent pas les interactions rÃ©elles</li>
    <li>Fausses assurances (tests trop â€œmockÃ©sâ€)</li>
    <li>Peuvent devenir fragiles si couplage Ã©levÃ©</li>
  </ul>
  <aside class="notes">
    Trop de mocks ou de stubs = perte de valeur du test. Les tests unitaires ne remplacent pas les tests d'intÃ©gration ou E2E.
  </aside>
</section>
<!-- Unit Tests: Bonnes pratiques -->
<section>
  <h2>Unit Tests â€” Bonnes pratiques</h2>
  <ul>
    <li>Tester un seul comportement par test</li>
    <li>Pas de dÃ©pendance rÃ©seau ou fichier</li>
    <li>Nommage clair des cas de test</li>
    <li>Inclure dans CI/CD</li>
  </ul>
  <aside class="notes">
    Un test doit Ã©chouer pour une seule raison. Les tests unitaires doivent Ãªtre maintenus Ã  chaque refactoring.
  </aside>
</section>

<!-- Integration Tests: But -->
<section>
  <h2>Integration Tests â€” But</h2>
  <ul>
    <li>Valider l'interaction entre plusieurs modules/services</li>
    <li>VÃ©rifier l'intÃ©gration avec bases de donnÃ©es, files, APIs externes</li>
  </ul>
  <aside class="notes">
    Les tests d'intÃ©gration attrapent les bugs d'assemblage qui Ã©chappent aux tests unitaires.
  </aside>
</section>
<!-- Integration Tests: Avantages -->
<section>
  <h2>Integration Tests â€” Avantages</h2>
  <ul>
    <li>DÃ©tecte les problÃ¨mes de configuration</li>
    <li>RepÃ¨re les incompatibilitÃ©s de schÃ©ma, protocole</li>
    <li>Permet de tester l'environnement de production â€œsimulÃ©â€</li>
  </ul>
  <aside class="notes">
    Les outils comme Testcontainers permettent de simuler les environnements rÃ©els via Docker.
  </aside>
</section>
<!-- Integration Tests: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>Integration Tests â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>Plus lents et coÃ»teux (setup/teardown DB, rÃ©seau)</li>
    <li>Flakiness si dÃ©pendances externes instables</li>
    <li>DifficultÃ© Ã  isoler la cause d'un Ã©chec</li>
  </ul>
  <aside class="notes">
    Attention Ã  ne pas tout tester via l'intÃ©grationâ€¯: la pyramide des tests reste valide.
  </aside>
</section>
<!-- Integration Tests: Bonnes pratiques -->
<section>
  <h2>Integration Tests â€” Bonnes pratiques</h2>
  <ul>
    <li>Utiliser des bases ou conteneurs Ã©phÃ©mÃ¨res</li>
    <li>Nettoyer les donnÃ©es entre les tests</li>
    <li>Tracer chaque Ã©tape (logs dÃ©diÃ©s)</li>
    <li>Limiter la portÃ©eâ€¯: pas de E2E dÃ©guisÃ©â€¯!</li>
  </ul>
  <aside class="notes">
    Les tests d'intÃ©gration doivent rester prÃ©visibles, reproductibles, et rapides autant que possible.
  </aside>
</section>

<!-- Contract Tests: But -->
<section>
  <h2>Contract Tests â€” But</h2>
  <ul>
    <li>Garantir que l'API (producteur) respecte bien le contrat attendu par les consommateurs</li>
    <li>Ã‰viter les rÃ©gressions d'interface lors des Ã©volutions</li>
  </ul>
  <aside class="notes">
    Le contract testing est critique en microservices et plateformes ouvertes (API publiques).
  </aside>
</section>
<!-- Contract Tests: Avantages -->
<section>
  <h2>Contract Tests â€” Avantages</h2>
  <ul>
    <li>Valide l'accord sur les formats d'Ã©change</li>
    <li>Permet la livraison indÃ©pendante des services</li>
    <li>DÃ©tecte les breaking changes avant mise en production</li>
  </ul>
  <aside class="notes">
    Les outils comme Pact facilitent la vÃ©rification automatique des contrats.
  </aside>
</section>
<!-- Contract Tests: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>Contract Tests â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>Couverture limitÃ©e Ã  l'API contractuelle</li>
    <li>Peut donner un faux sentiment de sÃ©curitÃ©</li>
    <li>Gestion complexe des versions de contrat</li>
  </ul>
  <aside class="notes">
    Le contract testing ne remplace pas l'intÃ©gration rÃ©elleâ€¯: il garantit l'interface, pas le comportement global.
  </aside>
</section>
<!-- Contract Tests: Bonnes pratiques -->
<section>
  <h2>Contract Tests â€” Bonnes pratiques</h2>
  <ul>
    <li>Centraliser les contrats (Pact Brokerâ€¦)</li>
    <li>VÃ©rifier en CI/CD Ã  chaque commit</li>
    <li>Mettre Ã  jour Ã  chaque changement d'API</li>
    <li>Inclure les cas limites et d'erreur</li>
  </ul>
  <aside class="notes">
    Toujours synchroniser la documentation de l'API et les tests de contrat.
  </aside>
</section>

<!-- E2E Tests: But -->
<section>
  <h2>E2E Tests â€” But</h2>
  <ul>
    <li>Valider le parcours utilisateur de bout en bout</li>
    <li>DÃ©tecter les rÃ©gressions sur le produit complet</li>
  </ul>
  <aside class="notes">
    Les tests E2E simulent le comportement d'un utilisateur rÃ©el Ã  travers l'UI ou l'API publique.
  </aside>
</section>
<!-- E2E Tests: Avantages -->
<section>
  <h2>E2E Tests â€” Avantages</h2>
  <ul>
    <li>VÃ©rifie le fonctionnement global</li>
    <li>Capte les bugs â€œintÃ©gration invisibleâ€</li>
    <li>Utilisables comme tests de non-rÃ©gression</li>
  </ul>
  <aside class="notes">
    Ils rassurent sur l'expÃ©rience rÃ©elle de l'utilisateur final, surtout aprÃ¨s refonte ou migration.
  </aside>
</section>
<!-- E2E Tests: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>E2E Tests â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>TrÃ¨s lents, fragiles (flaky) sur CI/CD</li>
    <li>ComplexitÃ© de setup et maintenance (mock data, users, auth, etc.)</li>
    <li>Difficiles Ã  dÃ©boguer en cas d'Ã©chec</li>
  </ul>
  <aside class="notes">
    Le ratio recommandÃ©â€¯: peu de tests E2E, beaucoup de tests unitaires/intÃ©gration.
  </aside>
</section>
<!-- E2E Tests: Bonnes pratiques -->
<section>
  <h2>E2E Tests â€” Bonnes pratiques</h2>
  <ul>
    <li>Automatiser screenshots & logs Ã  l'Ã©chec</li>
    <li>Utiliser des environnements de staging dÃ©diÃ©s</li>
    <li>Limiter aux parcours critiques</li>
    <li>RafraÃ®chir les donnÃ©es et comptes entre chaque run</li>
  </ul>
  <aside class="notes">
    Les tests E2E doivent Ãªtre stables et apporter une vraie valeur mÃ©tier.
  </aside>
</section>

<!-- Performance Testing: But -->
<section>
  <h2>Performance Testing â€” But</h2>
  <ul>
    <li>Ã‰valuer la robustesse sous chargeâ€¯: pics, volume, stress, endurance</li>
    <li>Identifier les goulets d'Ã©tranglement</li>
  </ul>
  <aside class="notes">
    Simuler la montÃ©e en charge ou l'activitÃ© rÃ©elle est essentiel pour prÃ©venir les dÃ©faillances en production.
  </aside>
</section>
<!-- Performance Testing: Avantages -->
<section>
  <h2>Performance Testing â€” Avantages</h2>
  <ul>
    <li>PrÃ©dire le comportement rÃ©el en production</li>
    <li>Ajuster la capacitÃ© ou le code avant l'incident</li>
    <li>Optimiser le coÃ»t d'infrastructure</li>
  </ul>
  <aside class="notes">
    Le monitoring permanent est complÃ©mentaireâ€¯: un test de performance ponctuel ne suffit pas.
  </aside>
</section>
<!-- Performance Testing: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>Performance Testing â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>Tests coÃ»teux en temps et ressources</li>
    <li>RÃ©sultats parfois difficiles Ã  interprÃ©ter</li>
    <li>Risques de â€œpolluerâ€ l'environnement rÃ©el si mal isolÃ©</li>
  </ul>
  <aside class="notes">
    Attention Ã  ne pas saturer une prodâ€¯: rÃ©aliser les tests sur un environnement dÃ©diÃ© ou simulÃ©.
  </aside>
</section>
<!-- Performance Testing: Bonnes pratiques -->
<section>
  <h2>Performance Testing â€” Bonnes pratiques</h2>
  <ul>
    <li>DÃ©finir les SLIs/SLOs (seuils acceptables)</li>
    <li>Automatiser la gÃ©nÃ©ration de rapports</li>
    <li>Rejouer les scÃ©narios sur plusieurs environnements</li>
    <li>CorrÃ©ler avec les mÃ©triques rÃ©elles de prod</li>
  </ul>
  <aside class="notes">
    L'automatisation et la rÃ©pÃ©tabilitÃ© sont clÃ©s pour progresser sur la durÃ©e.
  </aside>
</section>

<!-- Chaos Engineering: But -->
<section>
  <h2>Chaos Engineering â€” But</h2>
  <ul>
    <li>Valider la rÃ©silience en conditions rÃ©elles d'incident</li>
    <li>PrÃ©parer les Ã©quipes et les systÃ¨mes aux alÃ©as</li>
  </ul>
  <aside class="notes">
    L'ingÃ©nierie du chaos consiste Ã  provoquer des pannes pour observer la robustesse et la rÃ©action du systÃ¨me et de l'Ã©quipe.
  </aside>
</section>
<!-- Chaos Engineering: Avantages -->
<section>
  <h2>Chaos Engineering â€” Avantages</h2>
  <ul>
    <li>RÃ©vÃ¨le les points faibles non dÃ©tectÃ©s en test â€œnormalâ€</li>
    <li>Culture d'amÃ©lioration continue</li>
    <li>Augmente la confiance lors des incidents rÃ©els</li>
  </ul>
  <aside class="notes">
    Netflix et d'autres pionniers montrent que ces tests sont devenus indispensables en production cloud.
  </aside>
</section>
<!-- Chaos Engineering: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>Chaos Engineering â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>Peut perturber les utilisateurs si mal contrÃ´lÃ©</li>
    <li>ComplexitÃ© de la mise en Å“uvre et des scÃ©narios</li>
    <li>NÃ©cessite une culture d'entreprise mature</li>
  </ul>
  <aside class="notes">
    Ã€ ne pas pratiquer en prod sans feature flags, alerting, rollback automatisÃ©.
  </aside>
</section>
<!-- Chaos Engineering: Bonnes pratiques -->
<section>
  <h2>Chaos Engineering â€” Bonnes pratiques</h2>
  <ul>
    <li>DÃ©finir des blast radius (limites d'impact)</li>
    <li>Automatiser le retour Ã  l'Ã©tat normal</li>
    <li>Analyser chaque incident (post-mortem)</li>
    <li>IntÃ©grer au cycle d'amÃ©lioration continue</li>
  </ul>
  <aside class="notes">
    DÃ©marrer sur des environnements de staging, puis monter graduellement en prod.
  </aside>
</section>

<!-- SynthÃ¨se TestabilitÃ© -->
<section>
  <h2>SynthÃ¨se : pyramide des tests</h2>
  <img src="https://martinfowler.com/articles/practical-test-pyramid/test-pyramid.png" alt="Test Pyramid" style="max-width:60%">
  <ul>
    <li>Beaucoup d'unitaires, moins d'intÃ©gration, trÃ¨s peu de E2E</li>
    <li>Maintenir la rapiditÃ© et la robustesse du pipeline CI/CD</li>
  </ul>
  <img src="/public/images/testPyramid.png" />
  <aside class="notes">
    La pyramide des tests illustre le bon Ã©quilibre entre effort, couverture, coÃ»t et rapiditÃ©.
  </aside>
</section>

<!-- ObservabilitÃ© â€” AperÃ§u -->
<section>
  <h2>ObservabilitÃ© â€” AperÃ§u</h2>
  <ul>
    <li>Logging (journalisation)</li>
    <li>Metrics (mÃ©triques)</li>
    <li>Tracing (traÃ§age distribuÃ©)</li>
    <li>Monitoring</li>
    <li>Alerting</li>
  </ul>
  <aside class="notes">
    Les cinq piliers de l'observabilitÃ© forment un systÃ¨me nerveux pour comprendre et amÃ©liorer une architecture distribuÃ©e.
  </aside>
</section>

<!-- Logging: But -->
<section>
  <h2>Logging â€” But</h2>
  <ul>
    <li>Enregistrer tous les Ã©vÃ©nements importants (techniques et mÃ©tiers)</li>
    <li>Fournir une traÃ§abilitÃ© et un historique dÃ©taillÃ©</li>
  </ul>
  <aside class="notes">
    Les logs sont la premiÃ¨re source d'information lors d'un incidentâ€¯: erreurs, warnings, info mÃ©tier.
  </aside>
</section>
<!-- Logging: Avantages -->
<section>
  <h2>Logging â€” Avantages</h2>
  <ul>
    <li>Analyse rapide des incidents</li>
    <li>AuditabilitÃ© complÃ¨te</li>
    <li>Source de vÃ©ritÃ© pour les post-mortems</li>
  </ul>
  <aside class="notes">
    Avec un centralisateur (ELK, Graylog), l'analyse devient transversale et scalable.
  </aside>
</section>
<!-- Logging: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>Logging â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>Volume massifâ€¯: peut saturer le stockage ou le rÃ©seau</li>
    <li>DonnÃ©es sensibles exposÃ©es si logs non filtrÃ©s</li>
    <li>â€œLog Spamâ€â€¯: bruit inutile</li>
  </ul>
  <aside class="notes">
    Les logs doivent Ãªtre filtrÃ©s, rotatÃ©s et surveillÃ©s. Ne jamais logger de secrets ou de PII sans masquage.
  </aside>
</section>
<!-- Logging: Bonnes pratiques -->
<section>
  <h2>Logging â€” Bonnes pratiques</h2>
  <ul>
    <li>Log structurÃ© (JSONâ€¦)</li>
    <li>Niveau de sÃ©vÃ©ritÃ© appropriÃ©</li>
    <li>Centralisation et rotation</li>
    <li>Masquage des donnÃ©es sensibles</li>
  </ul>
  <aside class="notes">
    Toujours logguer au bon niveau (error, warn, info, debug) pour ne pas polluer les analyses.
  </aside>
</section>

<!-- Metrics: But -->
<section>
  <h2>Metrics â€” But</h2>
  <ul>
    <li>Mesurer l'Ã©tat et la performance du systÃ¨me</li>
    <li>Fournir des indicateurs quantitatifsâ€¯: CPU, mÃ©moire, requÃªtes, erreurs, temps de rÃ©ponseâ€¦</li>
  </ul>
  <aside class="notes">
    Les mÃ©triques servent Ã  Ã©tablir des seuils, des tendances, et dÃ©tecter les incidents en temps rÃ©el.
  </aside>
</section>
<!-- Metrics: Avantages -->
<section>
  <h2>Metrics â€” Avantages</h2>
  <ul>
    <li>Visualisation temps rÃ©el (Grafanaâ€¦)</li>
    <li>DÃ©tection proactive des anomalies</li>
    <li>Base pour auto-scaling et alerting</li>
  </ul>
  <aside class="notes">
    Les mÃ©triques forment le socle du monitoring moderne, notamment avec Prometheus et Grafana.
  </aside>
</section>
<!-- Metrics: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>Metrics â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>Trop d'indicateurs = â€œmetrics fatigueâ€</li>
    <li>Oubli de corrÃ©ler mÃ©triques et logs</li>
    <li>Peut masquer des problÃ¨mes de fond (ex. â€œtout va bien mais prod downâ€)</li>
  </ul>
  <aside class="notes">
    Choisir peu de mÃ©triques vraiment reprÃ©sentatives (SLI/SLO), et les rÃ©Ã©valuer rÃ©guliÃ¨rement.
  </aside>
</section>
<!-- Metrics: Bonnes pratiques -->
<section>
  <h2>Metrics â€” Bonnes pratiques</h2>
  <ul>
    <li>DÃ©finir des SLI/SLO (Service Level Indicators/Objectives)</li>
    <li>Automatiser les alertes sur seuils critiques</li>
    <li>CorrÃ©ler avec incidents et logs</li>
    <li>Revue pÃ©riodique des dashboards</li>
  </ul>
  <aside class="notes">
    Les mÃ©triques doivent Ãªtre actionnables et facilement accessibles Ã  toute l'Ã©quipe.
  </aside>
</section>

<!-- Tracing: But -->
<section>
  <h2>Tracing â€” But</h2>
  <ul>
    <li>Reconstituer le parcours d'une requÃªte Ã  travers plusieurs services</li>
    <li>Diagnostiquer les ralentissements ou Ã©checs distribuÃ©s</li>
  </ul>
  <aside class="notes">
    Le tracing distribuÃ© permet de comprendre l'enchaÃ®nement exact des traitements dans une architecture microservices.
  </aside>
</section>
<!-- Tracing: Avantages -->
<section>
  <h2>Tracing â€” Avantages</h2>
  <ul>
    <li>Identification des â€œspansâ€ lents</li>
    <li>DÃ©tection prÃ©cise des goulets d'Ã©tranglement</li>
    <li>Visualisation graphique du parcours complet</li>
  </ul>
  <aside class="notes">
    Outilsâ€¯: Jaeger, Zipkin, OpenTelemetry pour tracer automatiquement chaque requÃªte.
  </aside>
</section>
<!-- Tracing: InconvÃ©nients & Ã‰cueils -->
<section>
  <h2>Tracing â€” InconvÃ©nients & Ã‰cueils</h2>
  <ul>
    <li>Volume de donnÃ©es consÃ©quent</li>
    <li>ImplÃ©mentation parfois complexe</li>
    <li>NÃ©cessite un ID de corrÃ©lation cohÃ©rent partout</li>
  </ul>
  <aside class="notes">
    Le tracing n'a de valeur que si toutes les briques du systÃ¨me propagent les bons identifiants.
  </aside>
</section>
<!-- Tracing: Bonnes pratiques -->
<section>
  <h2>Tracing â€” Bonnes pratiques</h2>
  <ul>
    <li>Utiliser des trace IDs globaux</li>
    <li>Automatiser l'instrumentation via SDK (OpenTelemetryâ€¦)</li>
    <li>Visualiser et annoter les parcours mÃ©tiers clÃ©s</li>
  </ul>
  <aside class="notes">
    CorrÃ©ler systÃ©matiquement traces, logs, mÃ©triquesâ€¯: c'est l'observabilitÃ© â€œ360Â°â€.
  </aside>
</section>

<!-- Monitoring & Alerting -->
<section>
  <h2>Monitoring & Alerting â€” But</h2>
  <ul>
    <li>Surveiller la santÃ©, la performance et la disponibilitÃ© du systÃ¨me</li>
    <li>DÃ©clencher des alertes lors d'anomalies ou de dÃ©passements de seuils</li>
  </ul>
  <aside class="notes">
    Le monitoring doit couvrir tous les environnements (dev, staging, prod) pour prÃ©venir, pas seulement rÃ©agir.
  </aside>
</section>
<section>
  <h2>Monitoring & Alerting â€” Avantages</h2>
  <ul>
    <li>Intervention rapide sur incident</li>
    <li>Indispensable pour SLA/SLO</li>
    <li>Base de la fiabilitÃ© opÃ©rationnelle</li>
  </ul>
  <aside class="notes">
    Avec alerting intelligent (Alertmanager, PagerDuty), on rÃ©duit le MTTR (Mean Time To Recovery).
  </aside>
</section>
<section>
  <h2>Monitoring & Alerting â€” Limites & Ã‰cueils</h2>
  <ul>
    <li>Faux positifs/faux nÃ©gatifs si seuils mal calibrÃ©s</li>
    <li>â€œAlerte fatigueâ€ si trop de notifications</li>
    <li>Oubli de monitorer les dÃ©pendances externes</li>
  </ul>
  <aside class="notes">
    Mieux vaut moins d'alertes bien calibrÃ©es, rÃ©guliÃ¨rement testÃ©es, que trop d'alertes ignorÃ©es.
  </aside>
</section>
<section>
  <h2>Monitoring & Alerting â€” Bonnes pratiques</h2>
  <ul>
    <li>DÃ©finir qui reÃ§oit quelle alerte</li>
    <li>Tester les scÃ©narios de bout en bout (chaos)</li>
    <li>Automatiser l'escalade si non-rÃ©solu</li>
    <li>Revoir pÃ©riodiquement la pertinence des alertes</li>
  </ul>
  <aside class="notes">
    Les alertes doivent dÃ©clencher une action concrÃ¨te et utileâ€¯: Ã©vitez les â€œalertes de confortâ€.
  </aside>
</section>

<!-- SynthÃ¨se ObservabilitÃ© -->
<section>
  <h2>SynthÃ¨seâ€¯: observabilitÃ© 360Â°</h2>
  <ul>
    <li>CorrÃ©ler logs, mÃ©triques, traces pour une comprÃ©hension globale</li>
    <li>Rendre les signaux accessibles et comprÃ©hensibles</li>
    <li>Automatiser la rÃ©action aux incidents</li>
    <li>Outils : ELK, Prometheus, Grafana, Jaeger, Alertmanager, PagerDutyâ€¦</li>
  </ul>
  <aside class="notes">
    L'observabilitÃ© moderne permet de passer de la rÃ©action Ã  la prÃ©vention, et de l'incident Ã  l'amÃ©lioration continue.
  </aside>
</section>

<!-- Clarification : Logging vs Tracing -->
<section>
  <h2>Logging et Tracingâ€¯: est-ce la mÃªme choseâ€¯?</h2>
  <ul>
    <li>Quelle est la diffÃ©rence fondamentale entre logging et tracing dans un systÃ¨me distribuÃ©â€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: Logging vs Tracing</h2>
  <ul>
    <li>Le <b>logging</b> capture des Ã©vÃ©nements ou messages (erreurs, infos, Ã©tapes mÃ©tier) de faÃ§on linÃ©aire par service ou composant.</li>
    <li>Le <b>tracing</b> reconstitue le parcours complet d'une requÃªte Ã  travers tous les services, en chaÃ®nant les Ã©vÃ©nements corrÃ©lÃ©s par un identifiant unique (<code>traceId</code>).</li>
    <li>Conclusionâ€¯: Le logging dÃ©crit ce qui se passe localementâ€¯; le tracing Ã©claire le flux global et les dÃ©pendances.</li>
  </ul>
</section>

<!-- Clarification : Monitoring vs ObservabilitÃ© -->
<section>
  <h2>Monitoring et ObservabilitÃ©â€¯: mÃªme choseâ€¯?</h2>
  <ul>
    <li>En quoi le monitoring diffÃ¨re-t-il de l'observabilitÃ©â€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: Monitoring vs ObservabilitÃ©</h2>
  <ul>
    <li>Le <b>monitoring</b> collecte des mÃ©triques prÃ©-dÃ©finies (CPU, erreurs, latence) et dÃ©clenche des alertes sur seuils connus.</li>
    <li>L'<b>observabilitÃ©</b> permet de comprendre l'Ã©tat interne d'un systÃ¨me Ã  partir de signaux externesâ€¯: logs, mÃ©triques, traces. C'est une dÃ©marche d'analyse, pas seulement d'alerte.</li>
    <li>Conclusionâ€¯: le monitoring rÃ©pond Ã  Â«â€¯est-ce que Ã§a vaâ€¯?â€¯Â», l'observabilitÃ© Ã  Â«â€¯pourquoi Ã§a va (ou non)â€¯?â€¯Â»</li>
  </ul>
</section>

<!-- Clarification : Test d'intÃ©gration vs E2E -->
<section>
  <h2>Test d'intÃ©gration et E2E, est-ce pareilâ€¯?</h2>
  <ul>
    <li>Quelle diffÃ©rence entre test d'intÃ©gration et test end-to-endâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: IntÃ©gration vs E2E</h2>
  <ul>
    <li>Le <b>test d'intÃ©gration</b> vÃ©rifie la collaboration de plusieurs composants (DB, API, files) sans forcÃ©ment simuler l'utilisateur final.</li>
    <li>Le <b>test E2E</b> rejoue un parcours utilisateur complet, comme en prod, de l'UI Ã  la DB.</li>
    <li>Conclusionâ€¯: E2E = vision mÃ©tier rÃ©elleâ€¯; intÃ©gration = interaction technique.</li>
  </ul>
</section>

<!-- Clarification : Performance vs Chaos Testing -->
<section>
  <h2>Performance testing et Chaos engineeringâ€¯: mÃªme finalitÃ©â€¯?</h2>
  <ul>
    <li>Les tests de performance et de chaos servent-ils le mÃªme butâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: Performance vs Chaos</h2>
  <ul>
    <li><b>Performance testing</b> mesure les limites du systÃ¨me sous charge normale ou extrÃªmeâ€¯: vitesse, capacitÃ©, stabilitÃ©.</li>
    <li><b>Chaos engineering</b> injecte des dÃ©faillances (pannes, latence, coupures) pour vÃ©rifier la rÃ©silience rÃ©elle du systÃ¨me.</li>
    <li>Conclusionâ€¯: Performance = Â«â€¯jusqu'oÃ¹ Ã§a tientâ€¯?â€¯Â»â€¯; Chaos = Â«â€¯comment Ã§a rÃ©agit en cas d'incidentâ€¯?â€¯Â»</li>
  </ul>
</section>

<!-- Clarification : Contract vs Integration tests -->
<section>
  <h2>Contract Test vs Integration Testâ€¯: ambiguÃ¯tÃ© frÃ©quente</h2>
  <ul>
    <li>Un contract test garantit-il que deux services fonctionnent ensembleâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: Contract vs Integration</h2>
  <ul>
    <li>Le <b>contract test</b> vÃ©rifie que l'API respecte bien le contrat d'Ã©change (formats, statuts), pas le fonctionnement global de bout en bout.</li>
    <li>L'<b>integration test</b> vÃ©rifie le fonctionnement rÃ©el entre composants interconnectÃ©s, y compris la configuration, la DB, le rÃ©seau, etc.</li>
    <li>Conclusionâ€¯: Contract test = accord d'interface, Integration test = comportement global rÃ©el.</li>
  </ul>
</section>

<!-- Clarification : Logging vs Monitoring -->
<section>
  <h2>Logging et Monitoringâ€¯: est-ce la mÃªme catÃ©gorieâ€¯?</h2>
  <ul>
    <li>Les logs servent-ils Ã  monitorerâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: Logging vs Monitoring</h2>
  <ul>
    <li>Les <b>logs</b> donnent une vision fine d'Ã©vÃ©nements individuelsâ€¯: erreurs, actions mÃ©tiers, traces de debug.</li>
    <li>Le <b>monitoring</b> agrÃ¨ge des mÃ©triques issues du systÃ¨me (et parfois des logsâ€¯!) pour alerter sur un comportement anormal.</li>
    <li>Conclusionâ€¯: les logs sont une sourceâ€¯; le monitoring est une analyse continue pour dÃ©tecter les incidents.</li>
  </ul>
</section>

<!-- Clarification : Metrics vs Logs -->
<section>
  <h2>Metrics vs Logsâ€¯: comment choisirâ€¯?</h2>
  <ul>
    <li>Quand prÃ©fÃ©rer collecter une mÃ©trique plutÃ´t qu'un logâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: Metrics vs Logs</h2>
  <ul>
    <li>Une <b>mÃ©trique</b> mesure un phÃ©nomÃ¨ne quantitatif sur la durÃ©e (CPU, latence, taux d'erreur).</li>
    <li>Un <b>log</b> capture une information instantanÃ©e, utile pour l'analyse dÃ©taillÃ©e ou la reconstitution a posteriori.</li>
    <li>Conclusionâ€¯: mÃ©trique = tendanceâ€¯; log = dÃ©tail, diagnostic prÃ©cis.</li>
  </ul>
</section>

<!-- Clarification : Alerting vs Monitoring -->
<section>
  <h2>Monitoring et Alerting, confusionâ€¯?</h2>
  <ul>
    <li>L'alerting est-il une partie du monitoringâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: Alerting vs Monitoring</h2>
  <ul>
    <li>Le <b>monitoring</b> collecte et analyse des signauxâ€¯; l'<b>alerting</b> dÃ©clenche une action (notification, escalade) sur Ã©vÃ©nement anormal dÃ©tectÃ©.</li>
    <li>Conclusionâ€¯: monitoring = surveillanceâ€¯; alerting = rÃ©action automatisÃ©e.</li>
  </ul>
</section>

<!-- Clarification : Observability = Visibility ? -->
<section>
  <h2>ObservabilitÃ© = VisibilitÃ©â€¯?</h2>
  <ul>
    <li>Ces deux termes sont-ils interchangeablesâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: ObservabilitÃ© vs VisibilitÃ©</h2>
  <ul>
    <li>La <b>visibilitÃ©</b> dÃ©crit la capacitÃ© Ã  voir ce qui se passe (logs, dashboards).</li>
    <li>L'<b>observabilitÃ©</b> est la capacitÃ© Ã  comprendre pourquoi Ã§a se passe, Ã  partir des signaux collectÃ©s.</li>
    <li>Conclusionâ€¯: VisibilitÃ© = â€œvoirâ€â€¯; ObservabilitÃ© = â€œcomprendre et diagnostiquerâ€.</li>
  </ul>
</section>

<!-- Clarification : Tests automatisÃ©s vs manuels -->
<section>
  <h2>Tests automatisÃ©s vs manuelsâ€¯: oppositionâ€¯?</h2>
  <ul>
    <li>Les tests manuels sont-ils toujours infÃ©rieurs aux tests automatisÃ©sâ€¯?</li>
  </ul>
</section>
<section>
  <h2>RÃ©ponseâ€¯: AutomatisÃ©s vs Manuels</h2>
  <ul>
    <li>Les <b>tests automatisÃ©s</b> assurent la rÃ©pÃ©tabilitÃ©, la rapiditÃ© et la non-rÃ©gression continue.</li>
    <li>Les <b>tests manuels</b> sont indispensables pour l'exploration, les cas limites, l'UX, les scÃ©narios inattendus.</li>
    <li>Conclusionâ€¯: complÃ©mentaritÃ©, pas opposition.</li>
  </ul>
</section>

<!-- Quiz : QCM par type de test/obs -->
<section>
  <h2>Quiz TestabilitÃ© & ObservabilitÃ©</h2>
  <ol>
    <li>Ã€ quoi sert principalement un test de contratâ€¯?</li>
    <li>Quelle est la premiÃ¨re cause de logs inutilesâ€¯?</li>
    <li>Pourquoi limiter les tests E2Eâ€¯?</li>
    <li>Quel outil pour le tracing distribuÃ©â€¯?</li>
    <li>Un piÃ¨ge classique des alertesâ€¯?</li>
    <li>SLI/SLOâ€¯: c'est quoiâ€¯?</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponses au Quiz</h2>
  <ol>
    <li>Ã€ valider le respect du format d'Ã©change API entre producteur et consommateur.</li>
    <li>Le log spam ou l'absence de filtrage de niveau.</li>
    <li>Parce qu'ils sont longs, fragiles, coÃ»teux Ã  maintenir.</li>
    <li>Jaeger, Zipkin, OpenTelemetry.</li>
    <li>Le â€œbruitâ€ (trop d'alertes)â€¯: on finit par les ignorer.</li>
    <li>Indicateurs et objectifs de qualitÃ© de service.</li>
  </ol>
</section>

<!-- QCM 1 -->
<section>
  <h2>QCM</h2>
  <p><strong>Quel test vÃ©rifie l'interface d'une API sans exÃ©cuter tous les modules ?</strong></p>
  <ol type="a">
    <li>Test unitaire</li>
    <li>Contract test</li>
    <li>E2E test</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Contract test</strong> (b)â€¯: Il valide le respect du contrat d'API, indÃ©pendamment de l'implÃ©mentation complÃ¨te.</p>
</section>

<!-- QCM 2 -->
<section>
  <h2>QCM</h2>
  <p><strong>Le tracing distribuÃ© permet deâ€¦</strong></p>
  <ol type="a">
    <li>Visualiser le flux complet d'une requÃªte</li>
    <li>Archiver tous les logs</li>
    <li>Surveiller l'usage CPU</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Visualiser le flux complet d'une requÃªte</strong> (a)â€¯: Le tracing reconstitue le parcours d'une requÃªte dans tout le systÃ¨me.</p>
</section>

<!-- QCM 3 -->
<section>
  <h2>QCM</h2>
  <p><strong>Lequel n'est pas un outil de monitoringâ€¯?</strong></p>
  <ol type="a">
    <li>Prometheus</li>
    <li>Grafana</li>
    <li>Gatling</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Gatling</strong> (c)â€¯: Gatling est un outil de tests de performance, pas de monitoring.</p>
</section>

<!-- QCM 4 -->
<section>
  <h2>QCM</h2>
  <p><strong>Pourquoi limiter le nombre de tests E2Eâ€¯?</strong></p>
  <ol type="a">
    <li>C'est coÃ»teux et fragile</li>
    <li>Ã‡a garantit toute la qualitÃ©</li>
    <li>C'est inutile</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>C'est coÃ»teux et fragile</strong> (a)â€¯: Les E2E sont longs Ã  exÃ©cuter, sensibles Ã  l'environnement, et peu maintenables en grand nombre.</p>
</section>

<!-- QCM 5 -->
<section>
  <h2>QCM</h2>
  <p><strong>Une mÃ©trique bien choisie doit Ãªtreâ€¦</strong></p>
  <ol type="a">
    <li>Quantitative, actionnable, corrÃ©lable</li>
    <li>TrÃ¨s dÃ©taillÃ©e</li>
    <li>EnregistrÃ©e comme log</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Quantitative, actionnable, corrÃ©lable</strong> (a)â€¯: Les mÃ©triques servent Ã  piloter et alerter efficacement.</p>
</section>

<!-- QCM 6 -->
<section>
  <h2>QCM</h2>
  <p><strong>Le chaos engineering consiste Ã â€¦</strong></p>
  <ol type="a">
    <li>Injecter des pannes contrÃ´lÃ©es</li>
    <li>Optimiser les performances</li>
    <li>Automatiser le monitoring</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Injecter des pannes contrÃ´lÃ©es</strong> (a)â€¯: Le chaos engineering valide la rÃ©silience en conditions rÃ©elles.</p>
</section>

<!-- QCM 7 -->
<section>
  <h2>QCM</h2>
  <p><strong>La diffÃ©rence clÃ© entre un log et une mÃ©triqueâ€¯?</strong></p>
  <ol type="a">
    <li>Un log est Ã©vÃ©nementiel, la mÃ©trique est agrÃ©gÃ©e</li>
    <li>Un log mesure la latence</li>
    <li>Aucune</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Un log est Ã©vÃ©nementiel, la mÃ©trique est agrÃ©gÃ©e</strong> (a)â€¯: Les logs dÃ©taillent chaque Ã©vÃ©nementâ€¯; les mÃ©triques agrÃ¨gent l'information.</p>
</section>

<!-- QCM 8 -->
<section>
  <h2>QCM</h2>
  <p><strong>L'observabilitÃ© permetâ€¦</strong></p>
  <ol type="a">
    <li>De diagnostiquer les causes d'incident</li>
    <li>D'Ã©viter les logs</li>
    <li>De remplacer les tests</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>De diagnostiquer les causes d'incident</strong> (a)â€¯: L'observabilitÃ© offre une comprÃ©hension profonde du systÃ¨me.</p>
</section>

<!-- QCM 9 -->
<section>
  <h2>QCM</h2>
  <p><strong>Quelle est la meilleure pratique pour le loggingâ€¯?</strong></p>
  <ol type="a">
    <li>Logger tout au niveau debug</li>
    <li>Utiliser des niveaux et log structurÃ©</li>
    <li>Eviter toute rotation</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Utiliser des niveaux et log structurÃ©</strong> (b)â€¯: Les logs doivent Ãªtre hiÃ©rarchisÃ©s (info, warn, errorâ€¦) et structurÃ©s pour l'analyse.</p>
</section>

<!-- QCM 10 -->
<section>
  <h2>QCM</h2>
  <p><strong>Un test de performance mal conÃ§u peutâ€¦</strong></p>
  <ol type="a">
    <li>Saturer l'environnement de prod</li>
    <li>AmÃ©liorer l'expÃ©rience utilisateur</li>
    <li>Remplacer tous les tests d'intÃ©gration</li>
  </ol>
</section>
<section>
  <h2>RÃ©ponse</h2>
  <p><strong>Saturer l'environnement de prod</strong> (a)â€¯: Mal paramÃ©trÃ©, un test de charge peut causer une vraie panneâ€¯!</p>
</section>