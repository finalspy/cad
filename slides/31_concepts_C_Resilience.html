<!-- Slide d'introduction g√©n√©rale -->
<section data-background-image="/public/images/titre_concepts.jpg" 
          data-background-size="cover"
          data-background-opacity="0.5">
  <h2>Concepts cl√©s des applications distribu√©es</h2>
  <ul>
    <li>üî∫ Th√©or√®mes fondamentaux</li>
    <li>üåê Concepts et Techniques Cl√©s</li>
    <li>üß© Architecture et Design</li>
    <li><b>üõ°Ô∏è R√©silience et Scalabilit√©</b></li>
    <li>üß™ Tests et Observabilit√©</li>
    <li>üß† Gouvernance et √âquipes</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Vue d'ensemble des grands th√®mes.</li>
      <li>Annonce de la section R√©silience & Scalabilit√©.</li>
      <li>Mise en contexte p√©dagogique.</li>
    </ul>
  </aside>
</section>

<!-- Section R√©silience & Scalabilit√© -->
<section>
  <h2>üõ°Ô∏è R√©silience et Scalabilit√©</h2>
  <aside class="notes">
    <ul>
      <li>Objectif : Continuit√© de service face aux pannes et aux pics de charge.</li>
      <li>Principes cl√©s : design for failure, isolation, √©lasticit√©, observabilit√©.</li>
    </ul>
  </aside>
</section>

<!-- Scalabilit√© ‚Äî Aper√ßu -->
<section>
  <h2>Scalabilit√© ‚Äî Aper√ßu</h2>
  <ul>
    <li>Verticale</li>
    <li>Horizontale</li>
    <li>√âlastique</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Introduction aux trois types fondamentaux de scalabilit√©.</li>
    </ul>
  </aside>
</section>

<!-- Scalabilit√© ‚Äî Verticale -->
<section>
  <h2>Scalabilit√© ‚Äî Verticale</h2>
  <ul>
    <li>Augmentation des ressources (CPU, RAM) d'un seul n≈ìud</li>
    <li>Facile √† mettre en ≈ìuvre</li>
    <li>Limitation mat√©rielle et loi de Moore</li>
  </ul>
  <div class="mermaid">
  flowchart TB
    User[Utilisateur]
    Server1[Serveur unique + RAM + CPU + stockage]
    User --> Server1
    classDef highlight fill:#fde68a,stroke:#b45309,stroke-width:2px;
    class Server1 highlight
  </div>
  <aside class="notes">
    <ul>
      <li>Simple et rapide pour des mont√©es en charge modestes.</li>
      <li>Devient co√ªteux et plafonn√© avec l'√©volution des serveurs.</li>
      <li>Un seul serveur de plus en plus puissant</li>
      <li>Limites physiques/mat√©rielles</li>
      <li>Fr√©quent sur les bases de donn√©es historiques, applications monolithiques</li>
      <li>üèãÔ∏è‚Äç‚ôÇÔ∏è "On muscle la machine !"</li>
    </ul>
  </aside>
</section>

<!-- Scalabilit√© ‚Äî Horizontale -->
<section>
  <h2>Scalabilit√© ‚Äî Horizontale</h2>
  <ul>
    <li>Ajout de n≈ìuds identiques</li>
    <li>R√©partition de charge requise</li>
    <li>Gestion de la coh√©rence et du partitionnement</li>
  </ul>
  <div class="mermaid">
    flowchart TB
    User[Utilisateur]
    LB[Load Balancer]
    Server1[Serveur 1]
    Server2[Serveur 2]
    Server3[Serveur 3]
    User --> LB
    LB --> Server1
    LB --> Server2
    LB --> Server3
    classDef highlight fill:#a7f3d0,stroke:#047857,stroke-width:2px;
    class Server1,Server2,Server3 highlight
  </div>
  <aside class="notes">
    <ul>
      <li>Adapt√©e aux architectures cloud-native.</li>
      <li>Quasi-infinie mais complexifie le design.</li>
      <li>Plusieurs serveurs identiques</li>
      <li>Ajout de machines pour absorber plus de charge</li>
      <li>Plus adapt√© aux applications cloud/microservices</li>
      <li>üßë‚Äçü§ù‚Äçüßë "On multiplie les serveurs !"</li>
    </ul>
  </aside>
</section>

<!-- Scalabilit√© ‚Äî √âlastique -->
<section>
  <h2>Scalabilit√© ‚Äî √âlastique</h2>
  <ul>
    <li>Auto-ajustement dynamique selon la charge</li>
    <li>Optimisation du co√ªt en cloud</li>
    <li>Mont√©e et descente automatique</li>
  </ul>
  <div class="mermaid">
    flowchart TB
    User["Utilisateur"]
    LB["Load Balancer"]
    Server1["Serveur 1"]
    Server2["Serveur 2"]
    ServerN["Serveur N"]
    AutoScale["Auto-Scaling (Ajout/suppression de serveurs)"]
    User --> LB
    LB --> Server1
    LB --> Server2
    LB --> ServerN
    AutoScale -.-> Server1
    AutoScale -.-> Server2
    AutoScale -.-> ServerN
  </div>
  <aside class="notes">
    <ul>
      <li>Combine horizontal et vertical selon des r√®gles d√©finies.</li>
      <li>Essentiel pour les charges de travail variables.</li>
      <li>Le nombre de serveurs varie automatiquement selon la charge</li>
      <li>Pay-as-you-go (cloud), optimal pour pics et creux d'utilisation</li>
      <li>N√©cessite une architecture adapt√©e (stateless, etc.)</li>
      <li>üöÄ "L'infrastructure suit la demande en temps r√©el !"</li>
    </ul>
  </aside>
</section>

<!-- Synth√®se Scalabilit√© -->
<section>
  <h2>Comparatif Scalabilit√©</h2>
  <table>
    <thead>
      <tr>
        <th></th>
        <th>Verticale</th>
        <th>Horizontale</th>
        <th>√âlastique</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><b>Principe</b></td>
        <td>Augmenter la puissance d'un n≈ìud unique</td>
        <td>Ajouter des n≈ìuds identiques</td>
        <td>Adapter dynamiquement le nombre de n≈ìuds</td>
      </tr>
      <tr>
        <td><b>Co√ªt</b></td>
        <td>Augmente vite</td>
        <td>Lin√©raire, scalable</td>
        <td>Optimis√©, pay-as-you-go</td>
      </tr>
      <tr>
        <td><b>Limites</b></td>
        <td>Physiques/hardware</td>
        <td>Complexit√© logicielle</td>
        <td>Arch. adapt√©e, stateless requis</td>
      </tr>
      <tr>
        <td><b>Exemples</b></td>
        <td>Ancienne BDD monolithique</td>
        <td>Cluster web, microservices</td>
        <td>Cloud, e-commerce en soldes</td>
      </tr>
    </tbody>
  </table>
  <aside class="notes">
    <ul>
      <li>Permet de bien distinguer atouts et limites de chaque type de scalabilit√©.</li>
      <li>Utile pour conseiller un choix en fonction des besoins m√©tier ou du contexte technique.</li>
    </ul>
  </aside>
</section>

<!-- Scalabilit√© ‚Äî M√©canismes Intro -->
<section>
  <h2>Scalabilit√© ‚Äî M√©canismes</h2>
  <ul>
    <li>Auto-scaling</li>
    <li>Load balancing</li>
    <li>Sharding / Partitioning</li>
    <li>Caching distribu√©</li>
  </ul>
  <div class="mermaid">
    flowchart TB
      subgraph Utilisateurs
        User1(User)
        User2(User)
      end
      LB(Load Balancer)
      subgraph Serveurs
        S1[Instance 1]
        S2[Instance 2]
        S3[Instance 3]
        S4[Instance n]
      end
      User1 --> LB
      User2 --> LB
      LB --> S1
      LB --> S2
      LB --> S3
      LB -.-> S4
    </div>
    
  <aside class="notes">
    <ul>
      <li>Aper√ßu des principaux outils et techniques.</li>
      <li>Chacun d√©taill√© ensuite.</li>
    </ul>
  </aside>
</section>

<!-- Auto-scaling -->
<section>
  <h2>Auto-scaling</h2>
  <ul>
    <li>R√®gles bas√©es sur m√©triques (CPU, latence) ‚Äî <a href="https://aws.amazon.com/autoscaling/" target="_blank">Site AWS</a>, <a href="https://github.com/aws/aws-auto-scaling" target="_blank">GitHub</a></li>
    <li>Ajustement automatique du nombre d'instances</li>
  </ul>
  <div class="mermaid">
    flowchart LR
        Client((Client))
        LB([Load Balancer])
        ASG{{Auto Scaling Group}}
        S1[Instance 1]
        S2[Instance 2]
        S3[Instance n]
        Client --> LB --> ASG
        ASG --> S1
        ASG --> S2
        ASG -.-> S3
        ASG --Ajoute/retire--> S3
    </div>
      <aside class="notes">
    <ul>
      <li>Configurer via AWS console ou IaC.</li>
      <li>Assure une r√©ponse rapide aux variations de charge.</li>
      <li><b>Auto-scaling</b> : capacit√© d'ajuster automatiquement le nombre de ressources (VM, conteneurs) en fonction de la charge et de r√®gles pr√©d√©finies (CPU, m√©moire, requ√™tes/minute).</li>
      <li>Permet de dimensionner dynamiquement l'infrastructure et d'optimiser les co√ªts.</li>
      <li>Assure une r√©ponse rapide aux variations de charge.</li>
      <li>Les <b>Auto Scaling Groups</b> sont une notion AWS, mais le principe existe chez tous les grands clouds (GCP, Azure, OVHcloud, etc.).</li>
    </ul>
  </aside>
</section>

<!-- Load balancing -->
<section>
  <h2>Load Balancing</h2>
  <ul>
    <li>DNS round-robin, appliances mat√©rielles</li>
    <li>√âquilibreurs logiciels :
      <ul>
        <li><a href="https://nginx.org/" target="_blank">NGINX</a> ‚Äî <a href="https://github.com/nginx/nginx" target="_blank">GitHub</a></li>
        <li><a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank">AWS ELB</a></li>
      </ul>
    </li>
  </ul>
  <div class="mermaid">
    flowchart TB
        Client(Client)
        LB(Load Balancer)
        ServerA[Serveur A]
        ServerB[Serveur B]
        Client --> LB
        LB --> ServerA
        LB --> ServerB
    </div>
      <aside class="notes">
    <ul>
      <li>R√©partit le trafic pour garantir la haute disponibilit√©.</li>
      <li>Permet la mont√©e en charge et tol√©rance aux pannes.</li>
      <li>Un <b>load balancer</b> (√©quilibreur de charge) distribue les requ√™tes r√©seau entre plusieurs serveurs pour garantir la disponibilit√© et l'efficacit√©.</li>
      <li><b>DNS round-robin</b> : m√©thode simple de r√©partition o√π le serveur DNS retourne une adresse IP diff√©rente √† chaque requ√™te, permettant d'√©quilibrer la charge sur plusieurs serveurs.</li>
      <li>Une <b>appliance mat√©rielle</b> est un √©quipement r√©seau d√©di√© au load balancing, utilis√© pour les grosses infrastructures (ex : F5, Citrix NetScaler).</li>
      <li>Un <b>√©quilibreur logiciel</b> est une application (ex : NGINX, HAProxy) qui joue le m√™me r√¥le mais s'ex√©cute sur un serveur standard.</li>
      <li>R√©partit le trafic pour garantir la haute disponibilit√©.</li>
      <li>Permet la mont√©e en charge et tol√©rance aux pannes.</li>
    </ul>
  </aside>
</section>

<!-- Sharding / Partitioning -->
<section>
  <h2>Sharding / Partitioning</h2>
  <ul>
    <li>D√©coupage des donn√©es par cl√©, plage ou hash</li>
    <li>R√©duction de la contention et am√©lioration de l'I/O</li>
  </ul>
  <div class="mermaid">
    flowchart LR
      DB1[(Shard 1<br>ID 1-1000)]
      DB2[(Shard 2<br>ID 1001-2000)]
      App[Application]
      App --> DB1
      App --> DB2
  </div>
  <aside class="notes">
    <ul>
      <li>Important pour les bases de donn√©es massives.</li>
      <li>Chaque shard peut √™tre r√©pliqu√© pour la haute disponibilit√©.</li>
      <li><b>Sharding</b> : d√©coupage horizontal d'une base en plusieurs fragments ind√©pendants (shards), chacun stock√© sur un serveur distinct.</li>
      <li><b>Partitioning</b> : d√©coupage logique ou physique de la base, selon des crit√®res d√©finis (cl√©, plage de valeurs, hash).</li>
      <li>Exemple : d√©couper la base clients par plage d'ID pour r√©partir la charge. √Ä ne pas confondre avec la r√©plication, qui duplique les m√™mes donn√©es sur plusieurs n≈ìuds.</li>
    </ul>
  </aside>
</section>

<!-- Caching distribu√© -->
<section>
  <h2>Caching distribu√©</h2>
  <ul>
    <li>CDN pour contenu statique</li>
    <li><a href="https://redis.io/" target="_blank">Redis</a> ‚Äî <a href="https://github.com/redis/redis" target="_blank">GitHub</a>, <a href="https://memcached.org/" target="_blank">Memcached</a> ‚Äî <a href="https://github.com/memcached/memcached" target="_blank">GitHub</a></li>
  </ul>
  <div class="mermaid">
    flowchart LR
        App[Application]
        Cache[Cache distribu√© : Redis/Memcached]
        DB[(Base de donn√©es)]
        User[Utilisateur]
        User --> App
        App --> Cache
        App --> DB
        Cache --"Hit"--> App
        Cache --"Miss"--> DB
  </div>
  <aside class="notes">
    <ul>
      <li>R√©duit la latence et la charge sur la base de donn√©es.</li>
      <li>Am√©liore l'exp√©rience utilisateur pour acc√®s fr√©quents.</li>
      <li><b>CDN</b> (Content Delivery Network) : r√©seau mondial de serveurs plac√©s strat√©giquement pour diffuser rapidement du contenu statique (images, vid√©os, JS/CSS) √† proximit√© de l'utilisateur.</li>
      <li><b>Cache distribu√©</b> : m√©canisme de m√©moire partag√©e entre plusieurs instances applicatives, permettant de stocker temporairement des r√©sultats de requ√™tes pour r√©duire la latence et le trafic vers la base de donn√©es.</li>
      <li><b>Redis</b> : base de donn√©es cl√©/valeur ultra rapide, souvent utilis√©e comme cache, supporte la persistance et des structures de donn√©es avanc√©es.</li>
      <li><b>Memcached</b> : syst√®me de cache m√©moire distribu√©, tr√®s simple, rapide, mais ne supporte pas la persistance.</li>
      <li>R√©duit la latence et la charge sur la base de donn√©es.</li>
      <li>Am√©liore l'exp√©rience utilisateur pour acc√®s fr√©quents.</li>
    </ul>
  </aside>
</section>

<!-- Strat√©gies avanc√©es -->
<section>
  <h2>Strat√©gies avanc√©es</h2>
  <ul>
    <li><a href="https://cqrs.nu/" target="_blank">Pattern CQRS</a> ‚Äî <a href="https://github.com/artefactual/ogone-cqrs" target="_blank">GitHub</a></li>
    <li><a href="https://eventstore.org/" target="_blank">Event Sourcing</a> ‚Äî <a href="https://github.com/EventStore/EventStore" target="_blank">GitHub</a></li>
    <li><a href="https://aws.amazon.com/lambda/" target="_blank">AWS Lambda</a> ‚Äî <a href="https://github.com/openfaas/faas" target="_blank">OpenFaaS</a></li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Aper√ßu des patterns pour optimiser flux et co√ªts.</li>
      <li>Chaque notion d√©taill√©e ensuite.</li>
      <li><b>CQRS</b> : s√©paration des op√©rations de lecture et d'√©criture pour optimiser les performances et la scalabilit√©. Exemple : dans une appli e-commerce, lecture rapide des fiches produits via un mod√®le d√©di√©, √©criture des commandes via un autre.</li>
      <li><b>Event Sourcing</b> : toutes les modifications d'√©tat sont stock√©es sous forme d'√©v√©nements. Exemple : un compte bancaire garde l'historique de chaque op√©ration (cr√©dit, d√©bit), et l'√©tat courant est reconstruit par relecture des √©v√©nements.</li>
      <li><b>Lambda/Serverless</b> : ex√©cution de fonctions √† la demande, sans g√©rer de serveur. Exemple : g√©n√©rer une miniature d'image √† l'upload via une fonction Lambda, sans serveur d√©di√©.</li>
    </ul>
  </aside>
</section>

<!-- Aspects op√©rationnels -->
<section>
  <h2>Aspects op√©rationnels</h2>
  <ul>
    <li>Co√ªt vs Performance</li>
    <li>Monitoring & Alerting</li>
    <li>Tests de charge</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>√âquilibrer investissement et ROI.</li>
      <li>Surveiller pour pr√©venir plut√¥t que gu√©rir.</li>
      <li>Valider hypoth√®ses de dimensionnement.</li>
    </ul>
  </aside>
</section>

<!-- Co√ªt vs Performance -->
<section>
  <h2>Co√ªt vs Performance</h2>
  <ul>
    <li>Instances r√©serv√©es vs √† la demande</li>
    <li>Optimisation budg√©taire long terme</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>R√©server pour charge pr√©visible, on‚Äëdemand pour pics.</li>
      <li>Analyser co√ªts infrastructure r√©guli√®rement.</li>
    </ul>
  </aside>
</section>

<!-- Monitoring & Alerting -->
<section>
  <h2>Monitoring & Alerting</h2>
  <ul>
    <li><a href="https://prometheus.io/" target="_blank">Prometheus</a> ‚Äî <a href="https://github.com/prometheus/prometheus" target="_blank">GitHub</a></li>
    <li><a href="https://grafana.com/" target="_blank">Grafana</a> ‚Äî <a href="https://github.com/grafana/grafana" target="_blank">GitHub</a></li>
    <li><a href="https://prometheus.io/docs/alerting/latest/alertmanager/" target="_blank">Alertmanager</a></li>
    <li><a href="https://pagerduty.com/" target="_blank">PagerDuty</a></li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Dashboards pour visualisation temps r√©el.</li>
      <li>Alerte et escalade automatique pour incidents critiques.</li>
      <li><b>Monitoring</b> : surveillance continue de la sant√©, des performances et de la disponibilit√© des services via des m√©triques (CPU, latence, taux d'erreur‚Ä¶)</li>
      <li><b>Alerting</b> : notifications automatiques lors d'incidents ou de d√©passement de seuils critiques.</li>
      <li>Indicateurs courants : taux d'erreur HTTP 5xx, latence moyenne, taux d'utilisation CPU/m√©moire.</li>
      <li>Exemple d'alerte : ¬´ plus de 10% d'erreurs 500 sur 5 minutes ‚Üí alerte PagerDuty ¬ª.</li>
    </ul>
  </aside>
</section>

<!-- Tests de charge -->
<section>
  <h2>Tests de charge</h2>
  <ul>
    <li><a href="https://locust.io/" target="_blank">Locust</a></li>
    <li><a href="https://jmeter.apache.org/" target="_blank">Apache JMeter</a></li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Identifier les goulets d'√©tranglement.</li>
      <li>Int√©grer aux pipelines CI/CD.</li>
      <li><b>Test de charge</b> : simulation de nombreux utilisateurs/transactions pour mesurer la capacit√© et la robustesse du syst√®me.</li>
      <li>Exemple : tester la r√©sistance d'une API avec 1000 utilisateurs virtuels g√©n√©rant chacun 10 requ√™tes/s pendant 5 minutes.</li>
    </ul>
  </aside>
</section>

<!-- R√©silience ‚Äî Aper√ßu -->
<section>
  <h2>R√©silience ‚Äî Aper√ßu</h2>
  <ul>
    <li>Circuit Breaker</li>
    <li>Retry</li>
    <li>Timeout</li>
    <li>Bulkhead</li>
    <li>Graceful Degradation</li>
    <li>Self-Healing</li>
    <li>Failover</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Introduction aux principaux patterns.</li>
      <li>Chacun d√©taill√© individuellement.</li>
    </ul>
  </aside>
</section>

<!-- Circuit Breaker -->
<section>
  <h2>Circuit Breaker</h2>
  <ul>
    <li>Interrompt appels d√©faillants</li>
    <li>Evite effet cascade</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Prot√®ge contre la saturation du service en panne.</li>
      <li>S'ouvre et se referme selon seuils de r√©ussite.</li>
    </ul>
  </aside>
</section>

<!-- Retry -->
<section>
  <h2>Retry</h2>
  <ul>
    <li>Tentatives automatiques</li>
    <li>Backoff exponentiel et jitter</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Minimise les erreurs temporaires.</li>
      <li>Configurable pour diff√©rents codes d'erreur.</li>
      <li><b>Backoff :</b> d√©lai croissant entre chaque tentative pour √©viter la surcharge.</li>
      <li><b>Jitter :</b> ajout d'une variation al√©atoire au d√©lai pour √©viter les pics simultan√©s.</li>
    </ul>
  </aside>
</section>

<!-- Timeout -->
<section>
  <h2>Timeout</h2>
  <ul>
    <li>Limite de dur√©e pour appels</li>
    <li>Lib√©ration des ressources bloqu√©es</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Maintient r√©activit√© du syst√®me.</li>
      <li>Adapt√© aux sc√©narios critiques.</li>
    </ul>
  </aside>
</section>

<!-- Bulkhead -->
<section>
  <h2>Bulkhead</h2>
  <ul>
    <li>Isolation des sous-syst√®mes</li>
    <li>Limitation propagation des pannes</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>S'inspire des compartiments √©tanches d'un navire.</li>
      <li>Chaque compartiment a ses ressources d√©di√©es.</li>
      <li><b>Bulkhead</b> : principe d'isolation pour √©viter qu'une panne dans une partie du syst√®me n'affecte les autres. Exemple : s√©paration du service paiement et du service recommandations dans un site e-commerce. Si le service recommandations tombe, les paiements restent accessibles.</li>
    </ul>
  </aside>
</section>

<!-- Graceful Degradation -->
<!-- Graceful Degradation -->
<section>
  <h2>Graceful Degradation</h2>
  <ul>
    <li>D√©sactivation fonctions non critiques</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Maintien fonctionnalit√©s essentielles.</li>
      <li>R√©duit impact surcharge.</li>
      <li><b>Graceful Degradation</b> : capacit√© √† fournir un service d√©grad√© plut√¥t que de tomber en panne totale lors d'une surcharge ou d'un incident. Exemple : lors d'une forte affluence, d√©sactivation du chat en ligne ou des animations non essentielles pour pr√©server le c≈ìur de l'application.</li>
    </ul>
  </aside>
</section>

<!-- Self-Healing -->
<section>
  <h2>Self-Healing</h2>
  <ul>
    <li>Probes Kubernetes (liveness/readiness) ‚Äî <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank">Docs Kubernetes</a></li>
    <li>Red√©marrage automatique conteneurs</li>
  </ul>
  <div class="mermaid">
    flowchart LR
        Client(Client)
        LB(Load Balancer)
        Pod1[Pod App 1]
        Pod2[Pod App 2]
        Liveness[Liveness Probe]
        Readiness[Readiness Probe]
        Client --> LB
        LB --> Pod1
        LB --> Pod2
        Liveness -.-> Pod1
        Liveness -.-> Pod2
        Readiness -.-> Pod1
        Readiness -.-> Pod2
        Pod1 --"Restart si KO"--> Pod1
        Pod2 --"Restart si KO"--> Pod2
  </div>
  <aside class="notes">
    <ul>
      <li>Assure sant√© continue des services.</li>
      <li>R√©duit l'intervention manuelle.</li>
      <li><b>Self-healing</b> : capacit√© d'un syst√®me √† d√©tecter automatiquement ses propres d√©faillances et √† s'auto-r√©parer, sans intervention humaine.</li>
      <li><b>Liveness probe</b> : m√©canisme Kubernetes pour v√©rifier si un conteneur fonctionne toujours. Si lprobe √©choue, le conteneur est red√©marr√© automatiquement.</li>
      <li><b>Readiness probe</b> : v√©rifie si l'application est pr√™te √† recevoir du trafic. Tant qu'elle √©choue, le pod ne re√ßoit pas de trafic du load balancer.</li>
      <li>R√©duit l'intervention manuelle.</li>
    </ul>
  </aside>
</section>

<!-- Failover -->
<section>
  <h2>Failover</h2>
  <ul>
    <li>Active-passive ou active-active</li>
    <li>Bascule automatique site de secours</li>
  </ul>
  <aside class="notes">
    <ul>
      <li>Active-active offre tol√©rance maximale.</li>
      <li>Active-passive plus simple mais downtime court.</li>
      <li><b>Failover</b> : capacit√© √† basculer automatiquement vers un syst√®me de secours en cas de panne majeure. Exemple : si le datacenter principal tombe, redirection vers un site miroir h√©berg√© ailleurs.</li>
    </ul>
  </aside>
</section>

<!-- Slide : Retour d'exp√©rience r√©el ‚Äî Scalabilit√© chez Netflix -->
<section>
  <h2>Retour d'exp√©rience r√©el : Scalabilit√© chez Netflix</h2>
  <ul>
    <li>Migration du monolithe vers le cloud AWS pour accompagner la croissance.</li>
    <li><b>Probl√®mes initiaux :</b> limitations mat√©rielles, d√©ploiements lents, difficult√© √† supporter les pics.</li>
    <li><b>Solutions :</b> Microservices, auto-scaling, load balancing avanc√©, cache distribu√© (EVCache).</li>
    <li><b>R√©sultats :</b> Disponibilit√© 24/7, capacit√© √† servir des millions d'utilisateurs simultan√©s.</li>
    <li>Voir : <a href="https://www.infoq.com/presentations/netflix-architecture/" target="_blank">Netflix Architecture Evolution (InfoQ)</a></li>
  </ul>
  <aside class="notes">
    Netflix est pass√© de serveurs physiques √† AWS entre 2008 et 2016. Chaque microservice g√®re sa r√©silience‚ÄØ; l'infrastructure peut cro√Ætre ou d√©cro√Ætre dynamiquement. Ils ont invent√© le Chaos Engineering pour tester la r√©sistance en production.
  </aside>
</section>

<!-- Slide : Retour d'exp√©rience r√©el ‚Äî R√©silience chez ING Bank -->
<section>
  <h2>Retour d'exp√©rience r√©el : R√©silience chez ING Bank</h2>
  <ul>
    <li>Refonte compl√®te autour de CQRS, Event Sourcing et microservices pour les applications bancaires.</li>
    <li><b>Probl√®mes :</b> indisponibilit√© en p√©riode de pointe, difficult√©s d'audit, complexit√© du rollback.</li>
    <li><b>Solutions :</b> CQRS, Event Sourcing, circuit breaker, monitoring centralis√© (ELK, Prometheus).</li>
    <li><b>R√©sultats :</b> Haute r√©silience, conformit√© r√©glementaire, rollback facilit√©, moins d'incidents critiques.</li>
    <li>Voir : <a href="https://martinfowler.com/bliki/CQRS.html" target="_blank">Martin Fowler ‚Äî CQRS @ ING</a></li>
  </ul>
  <aside class="notes">
    ING a r√©ussi √† restaurer rapidement l'√©tat des comptes apr√®s des incidents gr√¢ce √† l'historique d'√©v√©nements. Les r√©gulateurs financiers appr√©cient la tra√ßabilit√© de chaque modification.
  </aside>
</section>

<!-- Slide : Retour d'exp√©rience ‚Äî Monitoring chez Zalando -->
<section>
  <h2>Retour d'exp√©rience ‚Äî Monitoring chez Zalando</h2>
  <ul>
    <li>Plus de 2000 microservices monitor√©s avec Prometheus et Grafana.</li>
    <li><b>D√©fis :</b> homog√©n√©it√© des m√©triques, gestion des alertes, visibilit√© transverse entre √©quipes.</li>
    <li><b>Le√ßons :</b> la r√©ussite du monitoring repose sur une culture DevOps et l'automatisation des dashboards et alertes.</li>
    <li>Voir : <a href="https://engineering.zalando.com/posts/2019/09/monitoring-at-scale-with-prometheus.html" target="_blank">Zalando Engineering ‚Äî Monitoring at Scale</a></li>
  </ul>
  <aside class="notes">
    Chaque √©quipe d√©veloppe ses propres m√©triques, mais Zalando a standardis√© l'export et la visualisation. Les incidents critiques sont remont√©s via PagerDuty, ce qui acc√©l√®re la r√©solution.
  </aside>
</section>

<!-- Quiz 1 -->
<section>
  <h2>Quiz : Scalabilit√© et R√©silience</h2>
  <ol>
    <li>Pourquoi Netflix a-t-il migr√© vers une architecture microservices cloud-native‚ÄØ?</li>
    <li>Quel est l'int√©r√™t d'un circuit breaker chez ING Bank‚ÄØ?</li>
    <li>Quelle est la diff√©rence entre scaling horizontal et vertical‚ÄØ?</li>
    <li>Citez un outil open-source utilis√© pour le monitoring √† grande √©chelle.</li>
    <li>Que se passe-t-il si le load balancer est mal configur√©‚ÄØ?</li>
  </ol>
  <aside class="notes">
    Ces questions permettent d'√©valuer la compr√©hension des principaux enjeux de la scalabilit√© et de la r√©silience dans des contextes r√©els.
  </aside>
</section>
<!-- R√©ponses Quiz 1 -->
<section>
  <h2>R√©ponses au Quiz</h2>
  <ol>
    <li>Pour l'√©lasticit√©, la disponibilit√© 24/7, absorber la croissance rapide et d√©ployer sans interruption.</li>
    <li>√âviter la propagation des pannes d'un service vers l'ensemble du SI. Le circuit breaker coupe les appels d√©faillants pour pr√©server le reste du syst√®me.</li>
    <li>Vertical‚ÄØ: augmenter la puissance d'un seul serveur. Horizontal‚ÄØ: ajouter des serveurs identiques. L'√©lastique combine les deux en s'adaptant √† la demande.</li>
    <li>Prometheus, Grafana, ELK‚Ä¶</li>
    <li>Certaine requ√™tes surchargent un serveur tandis que d'autres sont inactifs, risque de ralentissements ou pannes partielles.</li>
  </ol>
  <aside class="notes">
    La plupart de ces r√©ponses s'observent dans les √©tudes de cas Netflix, ING et Zalando. Discuter des cas d'incidents v√©cus dans l'industrie.
  </aside>
</section>

<!-- Quiz 2 -->
<section>
  <h2>Quiz : Cas concrets</h2>
  <ol>
    <li>Donnez une situation o√π le ‚Äúgraceful degradation‚Äù est pr√©f√©rable √† l'arr√™t complet du service.</li>
    <li>Pourquoi l'auto-scaling peut-il parfois g√©n√©rer des effets n√©gatifs (‚Äúthrashing‚Äù)‚ÄØ?</li>
    <li>√Ä quoi sert un CDN dans une architecture distribu√©e‚ÄØ?</li>
  </ol>
  <aside class="notes">
    Ces cas concrets sont r√©guli√®rement rencontr√©s dans l'exploitation d'applications cloud natives ou e-commerce.
  </aside>
</section>
<!-- R√©ponses Quiz 2 -->
<section>
  <h2>R√©ponses au Quiz</h2>
  <ol>
    <li>En cas de surcharge, on d√©sactive des fonctions secondaires (chat, recommandations) pour garantir le paiement ou le c≈ìur du service.</li>
    <li>Si la configuration est trop agressive, l'infrastructure peut osciller en permanence (d√©marrages/arr√™ts rapides), d'o√π co√ªts impr√©vus et instabilit√©.</li>
    <li>√Ä rapprocher les ressources statiques (images, vid√©os, CSS) de l'utilisateur pour acc√©l√©rer le chargement et all√©ger la charge des serveurs centraux.</li>
  </ol>
  <aside class="notes">
    Ce sont des sc√©narios r√©ellement observ√©s chez Netflix et de nombreux e-commer√ßants lors de pics de trafic ou d'√©v√©nements sp√©ciaux.
  </aside>
</section>

<!-- QCM 1 -->
<section>
  <h2>QCM 1 : Scalabilit√©</h2>
  <p>Quelle strat√©gie favorise la tol√©rance aux pannes dans une architecture distribu√©e‚ÄØ?</p>
  <ul>
    <li>A. Mise √† l'√©chelle verticale uniquement</li>
    <li>B. Ajout de redondance et r√©plication</li>
    <li>C. Suppression du cache</li>
    <li>D. Utilisation d'une seule base de donn√©es centrale</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 1</h2>
  <p><b>B. Ajout de redondance et r√©plication</b></p>
  <aside class="notes">
    La redondance et la r√©plication des ressources (serveurs, bases de donn√©es, etc.) permettent d'assurer la continuit√© de service m√™me en cas de panne.
  </aside>
</section>

<!-- QCM 2 -->
<section>
  <h2>QCM 2 : R√©silience</h2>
  <p>Quel est le r√¥le principal d'un circuit breaker‚ÄØ?</p>
  <ul>
    <li>A. Optimiser la latence du r√©seau</li>
    <li>B. Couper temporairement les appels vers un service d√©faillant</li>
    <li>C. R√©pliquer les donn√©es</li>
    <li>D. Contr√¥ler les acc√®s utilisateurs</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 2</h2>
  <p><b>B. Couper temporairement les appels vers un service d√©faillant</b></p>
  <aside class="notes">
    Le circuit breaker emp√™che qu'une panne locale ne se propage √† tout le syst√®me, en ouvrant le ‚Äúcircuit‚Äù et en stoppant temporairement les appels.
  </aside>
</section>

<!-- QCM 3 -->
<section>
  <h2>QCM 3 : Monitoring</h2>
  <p>Quel outil open source est souvent utilis√© pour la collecte de m√©triques et le monitoring distribu√©‚ÄØ?</p>
  <ul>
    <li>A. Apache JMeter</li>
    <li>B. Prometheus</li>
    <li>C. MongoDB</li>
    <li>D. Kubernetes</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 3</h2>
  <p><b>B. Prometheus</b></p>
  <aside class="notes">
    Prometheus collecte et stocke des m√©triques pour des infrastructures distribu√©es. Il s'int√®gre tr√®s bien avec Grafana pour la visualisation.
  </aside>
</section>

<!-- QCM 4 -->
<section>
  <h2>QCM 4 : Auto-scaling</h2>
  <p>Quel risque peut appara√Ætre en cas de mauvais param√©trage de l'auto-scaling‚ÄØ?</p>
  <ul>
    <li>A. Thrashing (cr√©ation/destruction en boucle d'instances)</li>
    <li>B. Temps de latence r√©duit</li>
    <li>C. R√©duction des co√ªts uniquement</li>
    <li>D. Blocage complet du syst√®me</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 4</h2>
  <p><b>A. Thrashing (cr√©ation/destruction en boucle d'instances)</b></p>
  <aside class="notes">
    Le thrashing survient quand l'auto-scaling ajoute et supprime trop rapidement des ressources, causant instabilit√© et surco√ªts.
  </aside>
</section>

<!-- QCM 5 -->
<section>
  <h2>QCM 5 : Caching distribu√©</h2>
  <p>Quel est le principal avantage d'un cache distribu√©‚ÄØ?</p>
  <ul>
    <li>A. Augmenter la s√©curit√© des acc√®s</li>
    <li>B. R√©duire la latence et la charge sur les bases de donn√©es</li>
    <li>C. Prot√©ger contre les attaques DDoS</li>
    <li>D. Optimiser le chiffrement des flux</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 5</h2>
  <p><b>B. R√©duire la latence et la charge sur les bases de donn√©es</b></p>
  <aside class="notes">
    Le cache distribu√© (Redis, Memcached‚Ä¶) sert √† acc√©l√©rer l'acc√®s aux donn√©es fr√©quemment consult√©es, ce qui diminue la pression sur la base de donn√©es.
  </aside>
</section>

<!-- QCM 6 -->
<section>
  <h2>QCM 6 : Load balancing</h2>
  <p>Quel type de load balancing est le plus simple √† mettre en place, mais souvent limit√©‚ÄØ?</p>
  <ul>
    <li>A. DNS round-robin</li>
    <li>B. Least Connections</li>
    <li>C. IP Hash</li>
    <li>D. Application Layer Load Balancer</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 6</h2>
  <p><b>A. DNS round-robin</b></p>
  <aside class="notes">
    Le round-robin au niveau DNS est tr√®s simple, mais ne prend pas en compte la sant√© ou la charge r√©elle des serveurs.
  </aside>
</section>

<!-- QCM 7 -->
<section>
  <h2>QCM 7 : Microservices</h2>
  <p>Quel est un risque courant des architectures microservices sans observabilit√© centralis√©e‚ÄØ?</p>
  <ul>
    <li>A. Surveillance simplifi√©e</li>
    <li>B. Difficult√© √† diagnostiquer et corriger les pannes</li>
    <li>C. R√©duction du besoin en documentation</li>
    <li>D. Moins de communication r√©seau</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 7</h2>
  <p><b>B. Difficult√© √† diagnostiquer et corriger les pannes</b></p>
  <aside class="notes">
    Sans observabilit√©, il est difficile de relier les incidents aux services en cause, ce qui complique le d√©pannage.
  </aside>
</section>

<!-- QCM 8 -->
<section>
  <h2>QCM 8 : Graceful Degradation</h2>
  <p>Que signifie ‚Äúgraceful degradation‚Äù‚ÄØ?</p>
  <ul>
    <li>A. Arr√™ter tous les services en cas d'incident</li>
    <li>B. Maintenir un service minimal fonctionnel lors d'une panne partielle</li>
    <li>C. Optimiser la base de donn√©es</li>
    <li>D. Doubler le nombre de serveurs</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 8</h2>
  <p><b>B. Maintenir un service minimal fonctionnel lors d'une panne partielle</b></p>
  <aside class="notes">
    L'id√©e est de d√©grader le service de fa√ßon contr√¥l√©e, pour √©viter une panne totale et pr√©server les fonctionnalit√©s essentielles.
  </aside>
</section>

<!-- QCM 9 -->
<section>
  <h2>QCM 9 : CDN</h2>
  <p>Quel est le r√¥le d'un CDN (Content Delivery Network)‚ÄØ?</p>
  <ul>
    <li>A. Optimiser le routage DNS</li>
    <li>B. Distribuer le contenu statique au plus proche des utilisateurs</li>
    <li>C. G√©rer les logs applicatifs</li>
    <li>D. S√©curiser les connexions SSH</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 9</h2>
  <p><b>B. Distribuer le contenu statique au plus proche des utilisateurs</b></p>
  <aside class="notes">
    Le CDN place des copies de contenus sur plusieurs points du globe pour acc√©l√©rer les chargements et limiter la charge du serveur central.
  </aside>
</section>

<!-- QCM 10 -->
<section>
  <h2>QCM 10 : Bulkhead</h2>
  <p>Le pattern ‚Äúbulkhead‚Äù sert √†‚ÄØ:</p>
  <ul>
    <li>A. R√©partir le cache sur plusieurs r√©gions</li>
    <li>B. Isoler des composants pour limiter la propagation des pannes</li>
    <li>C. Augmenter la bande passante r√©seau</li>
    <li>D. Chiffrer les √©changes de donn√©es</li>
  </ul>
</section>
<section>
  <h2>R√©ponse QCM 10</h2>
  <p><b>B. Isoler des composants pour limiter la propagation des pannes</b></p>
  <aside class="notes">
    Inspir√© des cloisons √©tanches d'un navire, le bulkhead pr√©serve le reste du syst√®me si une partie est en panne.
  </aside>
</section>

<!-- Sources -->
<section>
  <h2>üîó Sources & Bibliographie</h2>
  <ul>
    <li><a href="https://en.wikipedia.org/wiki/Scalability" target="_blank">Wikipedia - Scalability</a></li>
    <li><a href="https://martinfowler.com/articles/resilience.html" target="_blank">Martin Fowler - Patterns for Resilience</a></li>
    <li><a href="https://microservices.io/patterns/reliability/index.html" target="_blank">Microservices.io - Reliability Patterns</a></li>
    <li><a href="https://aws.amazon.com/autoscaling/" target="_blank">AWS - Auto Scaling</a></li>
    <li><a href="https://sre.google/sre-book/table-of-contents/" target="_blank">Google SRE Book - Table des mati√®res</a></li>
    <li><a href="https://opentelemetry.io/docs/" target="_blank">OpenTelemetry - Documentation</a></li>
    <li><a href="https://www.reactivemanifesto.org/" target="_blank">The Reactive Manifesto</a></li>
  </ul>
  <aside class="notes">
    <ul>
      <li>R√©f√©rences acad√©miques et industrielles pour approfondir.</li>
      <li>Livres blancs et RFC d'OpenTelemetry.</li>
      <li>Ressources d'impl√©mentations concr√®tes.</li>
    </ul>
  </aside>
</section>
